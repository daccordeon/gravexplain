\documentclass[paper-main.tex]{subfiles}

\begin{document}

In this section, we explore how our apparatus can be used to teach a selection of signal processing techniques. 
We use complex audio signals (such as music and speech) as a natural successor to the constant and wandering tones used in Sections~\ref{sec:single_tone} and~\ref{sec:viterbi_wandering}, respectively.
As complex audio signals are not quasi-monochromatic, the Viterbi algorithm used in Section~\ref{sec:viterbi_wandering} is not directly applicable here. 
Instead, we use a hierarchy of passive filters which suppress noise, yet do not assume any specific form of the signal, unlike the Fourier-based maximum likelihood filter which is tuned to the sinusoidal signals in Section~\ref{sec:single_tone} and Appendix~\ref{app:sinusoid_likelihood}.


We use the Michelson interferometer as an ``optical microphone'' to detect sound, replacing the components of a conventional microphone with a laser interferometer.
The only change to our apparatus is replacing the webcam with a photodiode to allow us to capture the higher frequencies necessary for speech and music (see Section~\ref{sec:photodiode}). 
Optical microphones have precedence in the laser microphones~\cite{laser_microphone} which are (or were historically) used in the defense industry and operate on a variety of related principles. 
Our objective is to play a recording of speech or music through the speaker attached to mirror M2 (see Fig.~\ref{fig:ifo_schematic_webcam}), record the resulting interference pattern, and then recover the original signal via a selection of signal processing techniques. 



The apparatus serves as an independent demonstration for a broader physics and engineering audience, particularly in undergraduate laboratories. 
We describe additional hardware components required for this demonstration in Section~\ref{sec:photodiode} and the initial results in Section~\ref{sec:initialResultsOpMic}. 
We consider a selection of filter techniques, details of which along with a summary of digital signal processing resources can be found in the Supplementary Material. 
In Section~\ref{sec:opticalMicResults}, we present the two best-performing techniques from the Supplementary Material. 



\subsection{Hardware modifications for the optical microphone}
\label{sec:photodiode}
The human ear can hear frequencies in the range of $\sim 20\,{\rm Hz}$--$20\,{\rm kHz}$. 
Speech intelligibility (the ability to understand speech) requires frequencies up to $3\,{\rm kHz}$ and music requires up to and beyond $8\,{\rm kHz}$. 
Therefore, the optical microphone requires a sample rate of at least $16\,{\rm kHz}$ to capture both speech and music (adjusting for the Nyquist frequency). 
This cannot be achieved with the webcam used in Sections~\ref{sec:single_tone} and ~\ref{sec:viterbi_wandering} as it has a sampling rate of $30\,{\rm Hz}$ and thus can only ``hear'' frequencies below $15\,{\rm Hz}$.
To overcome this issue, we use a photodiode~\footnote{A photodiode is an electrical component that acts as a regular diode when no light is incident on it, blocking any current flow in the reverse direction. As the intensity of incident light rises, it becomes increasingly conductive in the reverse direction.} at the output of the interferometer to achieve a sampling rate of $16\,{\rm kHz}$.

We place an OSRAM BPW21 photodiode in reverse-bias over an LM358 op-amp which together produce a voltage that depends on the incident intensity. 
The photodiode records the interference pattern at roughly the same off-center position as the webcam in Sections~\ref{sec:single_tone} and~\ref{sec:viterbi_wandering}, again chosen arbitrarily. 
The voltage signal from the photo-detector is captured by an MCP3008 $10$-bit analog-to-digital converter (ADC) connected to a Raspberry Pi Model 3 v1.2, which provides a convenient means to record the photodiode data.
Together, the circuit samples the signal at $\sim 16\,{\rm kHz}$. 
Resources for using the Raspberry~Pi and photodiode, including a circuit diagram, are described in the Supplementary Material.

Sampling any frequency component of the analog signal above the Nyquist frequency of $8\,{\rm kHz}$ leads to aliasing (folding of frequencies greater than half the sampling rate) into the detected range. We include an anti-aliasing Sallen-Key filter with a cut-off frequency of $8\,{\rm kHz}$ before the ADC to prevent this from happening. 
This component attenuates any frequencies above $8\,{\rm kHz}$ before they are digitally sampled. We also place a cloth screen over the face of the photodiode to reduce the incident intensity and avoid saturating the ADC -- an improvised, physical solution that could instead be replaced by scaling down the voltage electronically. This cloth screen was re-purposed grill cloth from a commercial speaker.


\subsection{Anti-aliased output}
\label{sec:initialResultsOpMic}


We test the optical microphone with a variety of recordings, including the speech of different people and music ranging from simple melodies and rhythms to songs. 
During recordings, care is taken to minimize activity around the demonstration to reduce environmental noise coupling into the interferometer. 
The timeseries data is then directly converted to a .wav file and played as an audio recording using the \texttt{scipy.io.wavfile.write} function in Python (see Appendix~\ref{app:code}).
When processing the results, we restrict our analysis to only the first $10\,{\rm s}$ of each observation (for efficiency), and only plot the first second here. 

The raw output of the optical microphone (with anti-aliasing) is noisy with a loud, continuous bass hum. 
This can be explained by looking at the power spectral density (PSD) of the background noise (i.e., the output with the speaker switched off), shown in Fig.~\ref{fig:psd_noise}. 
The spectrum is dominated by AC mains noise with power from the fundamental $50\,{\rm Hz}$ Australian mains power grid signal up to and beyond the $8$th harmonic. 
The mains signal is also present, but far weaker, in the background spectrum taken with the photodiode in darkness, suggesting that ambient lighting has a large contribution. 
Besides lighting, other possible contributions to the mains signal include air conditioning and the photodiode circuit itself. 
The appearance of harmonics of the mains noise might be due to the non-linearity in the system discussed in Section~\ref{sec:ifo}. 
The spectrum in Fig.~\ref{fig:psd_noise} also has a broad feature at around $750\,{\rm Hz}$, the origin of which is yet to be determined.
Environmental noise reduction for gravitational-wave detectors is an active area of research (see the Supplementary Material for further information and resources on this topic).




\begin{figure}
	\includegraphics[width=.5\textwidth]{figures/psd_podo_14_6.pdf}
	\caption{\label{fig:psd_noise}
Power spectral density (PSD) of background noise from the optical microphone (with the speaker off). 
We see strong power from the $50\,{\rm Hz}$ mains hum and its harmonics (most likely from the photodiode circuit and the roomâ€™s lighting and cooling). Otherwise, the PSD is fairly white except for a peak at around 0.75~kHz.
}
\end{figure}


\subsection{Optical microphone results}
\label{sec:opticalMicResults}

\begin{figure*}
\begin{center}
\includegraphics[width=0.8\textwidth]{figures/combined_highlight_results_melatos_labelled.pdf}
\caption{\label{fig:notchWienerLogMMSEResults}
Timeseries (left column) and frequency spectrum (right column) results with the optical microphone. 
The original input signal in the first row is a $1\,{\rm s}$ recording of an adult male voice (saying ``a cathode''). 
 The input signal is shifted by 0.12 s to the right to synchronize the manual delay from starting the recording with the Raspberry Pi and starting to play the source through the speaker. 
The second row shows the raw output from the optical microphone when the input from the first row is played. 
The third row shows the result of applying the notch and Wiener filters combined. 
The fourth row shows the result of applying the logMMSE estimator, where the rise at the start of the timeseries is an expected effect when filtering a signal of finite duration. 
}
\end{center}
\end{figure*}

We explore several filters to remove the $50\,{\rm Hz}$ mains hum and harmonics and improve the speech intelligibility of the recording.
The Supplementary Material describes a range of analysis techniques that can be used as examples for the undergraduate laboratory. 
All filters are tested on the same $1\,{\rm s}$ long speech recording.
The results of this section are shown in Fig.~\ref{fig:notchWienerLogMMSEResults}. 
In the figure, the left and right columns show the timeseries and frequency spectrum, respectively. 
The first row shows the input signal played through the speaker (see Fig.~\ref{fig:ifo_schematic_webcam}). 
The second row shows the raw output from the photodiode recording. 



In signal processing, the ideal filter would be one that:
(i) completely attenuates the undesired parts of the spectrum, 
(ii) does not change the rest of the spectrum, and 
(iii) smoothly transitions between these regions, as to not damage the time domain signal when seen under convolution. 
However, these three conditions cannot all hold at once. 
For example, if conditions (i) and (ii) hold, then the filter must be discontinuous at the boundary of the undesired region but this implies that the filter has ``infinite latency'' and so will affect (or damage) the time domain signal for infinite time.\cite{10.5555/151045}
Therefore, any filter must compromise between these three conditions. 
For speech intelligibility, this means that either: (i) some noise remains in the filtered recording, (ii) some of the speech content is lost as certain important frequencies are attenuated, or (iii) the speech is somewhat distorted in time.
All three of these cases can, when taken to the extreme, make the speech intelligibility worse than the unfiltered recording. 
Therefore, we choose filters that compromise between achieving the three conditions.


In this section, we present the results of two advanced signal processing techniques applied to the optical microphone recordings. 
The techniques are only briefly described here and we refer the reader to the Supplementary Material for further details and other analysis techniques. 



Firstly, we consider two signal processing techniques used in combination: the cascaded notch and the Wiener filter (see also the Supplementary Material). 
A notch filter removes signals within a specific frequency range. 
We want to remove the $50\,{\rm Hz}$ mains noise and harmonics, therefore we use a cascaded notch filter where each notch is centered on one of the harmonics. 
The Wiener filter is an advanced statistical technique that makes use of statistical information from the speech data and noise. 
It amplifies parts of the signal with a high signal-to-noise ratio while suppressing parts with a low signal-to-noise ratio. 
The results of the combined cascaded notch and Wiener filter are shown in the third row in Fig.~\ref{fig:notchWienerLogMMSEResults}. 
Most of the mains noise is removed; however, the recovered voice sounds muffled and is not understandable. 


Secondly, we apply a speech enhancement technique. 
Ref.~\cite{SubjectiveComparison} compares $13$ speech enhancement methods, finding the log minimum mean-square error (logMMSE) estimator to be the best, qualitatively, at recovering speech (see also the Supplementary Material). 
We use an existing implementation of the logMMSE from Ref.~\cite{logmmse}.  
The logMMSE estimator results are shown in the bottom panels in Fig.~\ref{fig:notchWienerLogMMSEResults}. 
We see significant attenuation of the mains harmonics and general smoothing of the spectrum. 
Most of the background noise is removed; however, the logMMSE still does not significantly enhance the speech as the voice sounds muffled and indistinct.


We find some improvement with music over speech. 
Simple chords and drums can be heard after filtering, but more composite sounds and complex melodies cannot be heard clearly. 
Our observations suggest that this is especially true for certain instruments; in particular flutes and violins sometimes canâ€™t be heard at all. 
This could be a perceptual effect or a frequency dependence somewhere in the optical microphone.
Speculating, perhaps the speaker-mirror coupling is stronger at low frequencies and thus instruments like electric bass and drums sound louder in the results.
To address these problems, we need to determine whether the signals that are audibly missing (the diction in the speech and complex melodies in music) are indeed being transmitted through the optical microphone at all. 
To determine this requires a better understanding of the system, as discussed in Section~\ref{sec:future_work}.



\end{document}
