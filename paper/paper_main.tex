% GravExplain
\documentclass[prb,preprint]{revtex4-1} 
% \documentclass[prb,preprint,letterpaper,noeprint,longbibliography,nodoi,footinbib]{revtex4-1} 

% Note that AJP uses the same style as Phys. Rev. B (prb).
% The AIP Style Manual\cite{AIPstylemanual} is an indispensable reference on good physics writing, covering everything from planning and organization to standard spellings and abbreviations.
% Most important of all, please familiarize yourself with the AJP Statement of Editorial Policy,\cite{editorsite} which describes the types of manuscripts that AJP publishes and the audience for which AJP authors are expected to write.
% We look forward to receiving your submission to AJP.
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{float}
\usepackage{mathtools}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{hyperref}
% \usepackage{siunitx}

\bibliographystyle{apsrev4-2}
% \setlength{\parindent}{0pt}

\newcommand{\jam}{\textcolor{magenta}}
\newcommand{\han}{\textcolor{orange}}


\begin{document}

% cover page
\section*{Project contributions}
% contributions clarify whatâ€™s to be assessed
James W. Gardner: all paper sections other than the introduction, design and making of the photodiode circuit, and all of the source code at \url{https://github.com/daccordeon/gravexplain}

Hannah Middleton: introduction of paper, design and making of the interferometer

Andrew Melatos, Robin Evans, William Moran: vital advice and comments throughout the project

\newpage

\title{GravExplain: Continuous gravitational wave searches in a table-top experiment}

\author{James W. Gardner}
\email{u6069809@anu.edu.au}
\affiliation{Research School of Physics, Australian National University, 60 Mills Rd, Acton ACT 2601 Australia}

\author{Hannah Middleton$^{(i)}$}
\email{hannah.middleton@unimelb.edu.au}
\author{Andrew Melatos$^{(i)}$}
\email{amelatos@unimelb.edu.au}
\author{Robin Evans$^{(ii)}$}
\email{robinje@unimelb.edu.au}
\author{William Moran$^{(ii)}$}
\email{wmoran@unimelb.edu.au}
\affiliation{School of Physics$^{(i)}$ and Department of Electrical and Electronic Engineering$^{(ii)}$, University of Melbourne, Parkville, VIC, 3010, Australia}
\affiliation{OzGrav-Melbourne, Australian Research Council Centre of Excellence for Gravitational Wave Discovery}

% Summer 2019/2020
\date{\today}

% AJP requires an abstract for all regular article submissions.
\begin{abstract}
Continuous gravitational wave searches use sophisticated statistical techniques to search for signals in noisy data. We demonstrate some of these techniques with a table-top Michelson interferometer, namely the Viterbi algorithm for recovering injected tones and a signal processing filter pipeline. We also use the same experiment to demonstrate an optical microphone capable of playing back simple recordings of injected audio.
 
\end{abstract}

\maketitle

% cover page that attributes all contributions

\section{Introduction}

% general gw intro
In 2015 gravitational waves were observed for the first time from the merger of two black holes in a binary system.~\cite{GW150914} 
The observation, made by the Laser Interferometer Gravitational-wave Observatory~\citep[LIGO]{AdvancedLIGO:2015}, marked a breakthrough in modern astrophysics and provides a new means to observe the universe. 
Since 2015, the LIGO and Virgo~\cite{AdvancedVirgo:2015} observatories have made numerous detections of binary black hole~\cite{GW151226,GW170104,GW170814} and binary neutron star~\cite{GW170817,GW170817multi,GW190425} mergers. 
In recent years there has been an increased public interest in gravitational-wave science. 
Many gravitational wave research groups around the world have produced demonstrations and activities to aid in explaining this topic to a general audience.
Activities range from online data analysis tutorials,~\cite{GWOSC:online,LOSC:2015} hands-on demonstrations, phone apps,~\cite{LaserLabs:online,SciVR:online} and online games,~\cite{BlackHoleHunter:online} to exhibitions,\cite{L2URSSE} artistic interpretation, and musical performance \han{add refs}. 



% what are gws and how do we detect them...
Gravitational waves are a prediction of Einstein's theory of general relativity. 
They are disturbances in spacetime caused by the acceleration of massive objects. 
The effect of gravitational waves is to change distances; a ``stretch and squeeze'' effect. 
Observatories such as LIGO, Virgo, and KAGRA~\cite{KAGRA:2013} are laser interferometers; they use the interference of laser light to measure changes in distance. 
The observatories themselves are extremely complex devices, however they are based on the Michelson interferometer. 
Table-top Michelson interferometers are commonly used by gravitational-wave research groups to demonstrate this science to non-specialist audiences~\cite{ThorLabsIFO,NikhefIFO}\han{add exhibit info when available} and they are often used in undergraduate lab experiments~\cite{UgoliniEtAl:2019}. 


% continuous gws
To date the network of gravitational-wave observatories have observed short-duration transient signals~\cite{GWTC-1:2018,GWOSC:online}. 
However, these observatories are also searching for continuous gravitational waves; persistent, periodic signals which should be present in the data for many months or years. 
A prime target for these searches are rotating neutron stars. 
So far many searches have been made of LIGO and Virgo data, however no detection has been made so far.


% overview
In this article we describe how a Michelson interferometer can be used to demonstrate the search for continuous gravitational waves to a general audience. 
The techniques used are very similar to those used by researchers to search for continuous waves in LIGO and Virgo data.
In Section~\ref{sec:ifo} we detail the interferometer set-up, Section~\ref{sec:single_tone} demonstrates observing a single tone, Section~\ref{sec:viterbi_wandering} details tracking a wandering frequency tone, and Section~\ref{sec:optical_microphone} extends the set-up to be able to capture complex audio, such as music and speech.


% \section{Method and results}
\section{Table-top gravitational wave science}
\label{sec:ifo}

Detectable gravitational waves are caused by the most violent events in the universe. Like two massive black-holes merging with each other. Even so, the effects they produce are on the order of one part in $10^{21}$ for our best detectors\cite{GW150914}. Given the impossibility of such detection with a table-top experiment, we demonstrate the same techniques but for observing sound waves.

\subsection{Michelson interferometry}
% hardware: path difference, virtual thin film interference

A Michelson interferometer is a well-known optics configuration used in many undergraduate and research labs, including in the detectors for gravitational waves. A laser beam of coherent (monochromatic and equal phase) light is split into two arms at right-angles to each other, travelling down and back from a mirror at the end of each arm. The beams return to interfere at a screen and produce a pattern of concentric, circular fringes. The configuration is shown in Figure~\ref{fig:ifo_schematic_webcam}.

\begin{figure}
	\includegraphics[width=0.8\textwidth]{figures/ifo_schematic_webcam.pdf}
	\caption{Michelson interferometer schematic, interference pattern is recorded by a webcam}
	\label{fig:ifo_schematic_webcam}
\end{figure}
% Note that we do not include the common compensating plate that equalises the amount of time spent in glass for each beam. We did not find it necessary to include it to be able to demonstrate the results desired.

The interference pattern, as shown in Figure~\ref{fig:interference_pattern}, is due to the path difference between the two arms resulting in a phase difference between the two beams when they meet at the screen. This path difference is perhaps better seen as the perpendicular separation between one mirror and the virtual image of the other.
For an aligned configuration and a fixed separation, the phase difference at a point only depends on the angle from the centre-line of the beam, and so the pattern is circularly symmetric.
The intensity, $I$, of this pattern at a particular angle is given by Equation~\ref{eq:intensity_result} below. Where A is the amplitude of the electric field of the beam, d is the separation (or the difference in the arm lengths), $\theta$ is the angle from the centre-line to the point on the screen, and $\lambda$ is the wavelength, 532nm, of the laser (see Appendix~\ref{app:intensity_derivation} for the derivation to get to this equation).
\begin{equation}
\label{eq:intensity_result}
I = 2 A^2 (1+\cos{\phi}), \; \phi = \frac{4 \pi d \cos{\theta}}{\lambda}
\end{equation}

This equation means that the intensity changes non-linearly with a small change in separation, as in Equation~\ref{eq:intensity_change} (see Appendix~\ref{app:intensity_derivation} again for the derivation). This makes the problem of extracting the original signal more difficult.

\begin{equation}
\label{eq:intensity_change}
	\frac{\delta I}{\delta d} = \frac{- 8 \pi A^2 \cos{\theta}}{\lambda} \sin{(\frac{4 \pi \cos{\theta}}{\lambda} d)}
\end{equation}

\begin{figure}
	\includegraphics[width=\textwidth]{figures/webcam_still0.pdf}
	\caption{Interference pattern from Michelson interferometer as viewed by webcam from below (hence why the pattern appears non-circular), red dot indicates point where intensity time series was measured, the central fringe is approximately 5mm across}
	\label{fig:interference_pattern}
\end{figure}

% A note that while the interference pattern appears similar to the Airy pattern produced by a circular aperture, they are not in fact the same geometry.


\section{Observing a single tone}
\label{sec:single_tone}
% the webcam method
% how to analyse video, python OpenCV2

\subsection{Method}

We demonstrate a signal source with a 0.5W speaker stuck to the back of one of the mirrors. This speaker was obtained from a standard commercial 3.5mm jack input, USB powered pair of speakers. Alternatively, a speaker can be driven by a function generator and power plugs.
As the speaker deforms to play something, the mirror moves with a change in separation, $\delta d$, as some function of the amplitude and frequency of the sound. The motion of the fringes follows the motion of the mirror and therefore the speaker at the same frequency. If the fringe motion is small, then changes in the intensity at some point on the screen follow the frequency of the injected (played) audio but with amplitude given by a transfer function that accounts for the coupling and resonance of the speaker-mirror system.
Large fringe motion means that multiple fringes can pass over the measured point in a single speaker deformation, such over-counting would artificially raise the measured frequency. As such, any motion of the fringes, and so of the speaker, must be kept small.


\subsection{Results}

We measure the intensity at a point on the screen with a standard commercial USB webcam, sampling at 30Hz (or 30 fps). This limits the spectral content of signals we can observe to be under the Nyquist frequency of 15Hz. This isnâ€™t an issue to demonstrate what we want, but see later Section~\ref{sec:photodiode} to raise this limit to audible frequencies. While playing a tone under 15Hz through the speaker for a minute, we recorded the interference pattern with the webcam.
Then, at an off-centre pixel as seen in Figure~\ref{fig:interference_pattern}, we take the green-channel of the RGB video as approximate to the total intensity, as the laser is monochromatic green light. We can play this time series of intensity over time as an audio recording, and the tone is clearly heard. Taking the Fourier transform of this signal also strongly shows the injected tone at the correct frequency, as shown in Figure~\ref{fig:webcam_spectrum}. Therefore, weâ€™re confident that weâ€™ll be able to track input frequencies.

\begin{figure}
	\includegraphics[width=\textwidth]{figures/webcam_expt_4_0209-cropped.pdf}
	\caption{Spectrum of intensity time series of interference pattern as captured by a webcam for an injected tone of 2.09Hz hitting the interferometer, injected fundamental frequency and harmonics thereof clearly present in spectrum}
	\label{fig:webcam_spectrum}
\end{figure}

\section{Observing a wandering tone}
\label{sec:viterbi_wandering}
% Tracking tones with the Viterbi algorithm
% explaination and successful application
% lean on the continuous gravitational waves angle

\jam{need to cite the various searches here}

Continuous gravitational wave searches look for signals that change frequency slowly over time. This means that finding the signal isnâ€™t as simple as searching for a peak in the spectral content for the full observing run.
Instead, the common method is to split the observed time series into bins of time, compute the spectra for each time interval, and then find the most likely path for the signal frequency through the spectra over time. The plot of spectra over time is known as a spectrogram.
This turns the problem of searching for a signal in noisy data into one of finding the best path through a grid of weights (here the Fourier amplitudes). We restrict the path-finding to some rate of frequency change of time, usually informed by a physical model, but here just set to 0.11 Hz per second to make it one frequency bin per every time bin.


\subsection{The Viterbi algorithm}

The Viterbi algorithm is a path-finding algorithm that solves this particular problem of going from one side of a grid to the other. See Appendix~\ref{app:viterbi} for the full details of the algorithm in this particular implementation.
Abstractly speaking through, given a weighted graph (e.g.\ the spectrogram), a sensible sequence of subgraphs (e.g.\ the spectra at each time bin), and any restrictions on connectivity (e.g.\ the allowed amount of source frequency change over time), the Viterbi algorithm will find the best path to each node in the next subgraph all the way from the first subgraph at each iteration. At the end, it selects the overall best path from the first to the last subgraph (here, from the start to end time), this overall best path is called the Viterbi path.

\subsection{Results}

To demonstrate this technique, we inject a tone that wanders in frequency over time, remembering to integrate up the phase change over time (see Appendix~\ref{app:phase_gotcha} for why). Alternatively, a function generator can be slowly controlled to achieve the same input. Shown in Figure~\ref{fig:viterbi_overlay} is the resultant spectrogram of the observed signal, along with the Viterbi path and the injected signal.
To the eye, the Viterbi algorithm recovers the injected frequency over time, likely due to the high signal-to-noise ratio (SNR). Quantifying this, the Viterbi path stays within one frequency bin (approximately 0.3Hz) of the injected tone for 94\% of the run. Note that the signal initially moves too quickly (more than 0.11 Hz per second) for Viterbi to track, and that there appears to be an anomaly at 150s, likely a disturbance around the interferometer.
Decreasing the signal-to-noise ratio closer to unity or increasing the allowed change in frequency over time causes Viterbi to more easily lose the signal. However, the demonstration clearly shows the ability to recover a continuous wave with the Viterbi algorithm, just as is done in continuous gravitational wave searches.


\begin{figure}
	\includegraphics[width=\textwidth]{figures/expt_overlay_2_viterbi_test_webcam.pdf}
	\caption{Spectrogram of observed signal overlaid with white crosses for the Viterbi path and pink dots for the injected signal, notice the high correlation between them indicating that the signal is able to be recovered; also note the deviation at the start when the signal moves too quickly and just before the background anomaly at 150s}
	\label{fig:viterbi_overlay}
\end{figure}

\section{Complex audio}
\label{sec:optical_microphone}
% Optical microphone
% aim of optical microphone: play back injected sounds

The natural succession to simple tones is to study complex audio signals, such as music and speech.
The Viterbi algorithm and tracking more broadly is not applicable to these signals. Compare a single tone that slowly, continuously changes frequency to music and speech which consist of a broad spectrum that is constantly changing.
Instead, the interest here is in being able to record and play-back these complex audio signals, rather than track them. Using the interferometer to do so makes it, in ensemble with the measuring device, an â€˜optical microphoneâ€™, using light to capture sound.


Advanced signal processing is required to extract gravitational wave signals from very noisy observational data. Recovering audio from an optical microphone requires related signal processing. Although far simpler, it serves as another useful demonstration.

\subsection{The photodiode method}
\label{sec:photodiode}
% advanced method: explain how we capture data

For an optical microphone to be sensitive to speech and music it needs a frequency response far higher than the 30Hz of a standard webcam. Both speech and music need at least kHz range, with speech intelligibility requiring up to 3kHz and music preferably up to and beyond 8kHz. This can be addressed by using a high-speed webcam, or more simply, by using a photodiode as the measuring device.


A photodiode is an electrical component that acts as a regular diode (blocking any current flow in the reverse direction) when no light is incident on it, but becomes more and more conductive in the reverse direction as the intensity of incident light increases. 
Fundamentally, a current is created in the photodiode by the photo-electric effect. Placing a photodiode in reverse-bias over an op-amp creates a photo-detector that will produce a voltage dependent approximately linearly to the incident intensity. \jam{How sound is this approximation?} This experiment had the photodiode in the interference pattern at roughly the same spot as the webcam was monitoring previously, just off-centre.


The voltage signal from the photo-detector is captured by a 10-bit analog-to-digital converter (ADC) connected to the special purpose input (SPI) pins of a Raspberry Pi, in the standard configuration. This digitally samples the signal at roughly 16kHz. As such, any frequency component of the analog signal above the Nyquist frequency of 8kHz would be aliased down into the detected range.
To prevent this, an anti-aliasing Sallen-Key filter tuned to 16kHz is included before the ADC. This component attenuates any frequencies above 8kHz, before they get digitally sampled.
Itâ€™s not immediately clear whatâ€™s limiting the sample rate to 16kHz, but it is likely non-optimal reading of the ADC by the Pi script.
% The ADC used (MCP3008) is quoted at 200kHz (or ksps, kilo samples per second).


The entire circuit diagram is detailed and shown in Appendix~\ref{app:circuit_diagram}. The updated schematic is shown in Figure~\ref{fig:ifo_schematic_podo} and a picture taken of the experiment, showing the interferometer, the circuit, and the Pi, is shown in Figure~\ref{fig:setup_pic2}.

\begin{figure}
	\includegraphics[width=0.8\textwidth]{figures/ifo_schematic_photodiode.pdf}
	\caption{Michelson interferometer schematic, a part of the interference pattern is recorded by a photodiode}
	\label{fig:ifo_schematic_podo}
\end{figure}

\begin{figure}
	\includegraphics[width=0.8\textwidth]{figures/setup_pic2.pdf}
	\caption{Picture taken of the optical microphone set-up, showing the Michelson interferometer, the photodiode (in an insert), the circuit, and the Raspberry Pi.}
	\label{fig:setup_pic2}
\end{figure}

\subsection{Initial results}
% breakdown of all the filters used along the way

The optical microphone was tested on recordings of one human talking and on music ranging from simple melodies to full tracks. Each recording was around one minute long with processing done on ten second segments. For each observation, the audio was played through the speaker with minimal activity around interferometer as the Pi script recorded the signal. The saved time series was then directly converted to a .wav file and played as an audio recording, using the \textbf{scipy.io.wavfile.write}\cite{scipy} implementation in Python\cite{python}.


These initial recordings were extremely noisy and painful to listen to, with a loud bass sound throughout. Spectra of all of these recordings showed a dominant mains hum at 50Hz with strong power up to and beyond the 8th harmonic thereof. This power is also present with the speaker off, as is shown in Figure~\ref{fig:psd_noise}, and also weakly when monitoring with the photodiode in complete darkness.

\begin{figure}%[H]
	\includegraphics[width=\textwidth]{figures/podo_noise_psd_zoom-cropped.pdf}
	\caption{Power spectral density (PSD) of the optical microphone system with no injected audio (i.e.\ with the speaker off), show high power in the 50Hz mains hum and its harmonics (most likely from the photodiode circuit and the ambient lighting), otherwise is a fairly white spectrum except for the broad, shallow maximum at 750Hz}
	\label{fig:psd_noise}
\end{figure}

\subsection{Filters applied}

Early attempts to remove the mains hum included zeroing the channel of each 50Hz harmonic, this is effectively using a rectangular comb filter. Applying a filter (multiplying by a function) in frequency space is equivalent to convolving the signal with the inverse Fourier transform of that filter. While this did remove the mains harmonics, it also destroyed the rest of the signal.


Attempting to low-pass the signal did better (to the ear) but was also problematic as the harmonics are all over the 100Hz-1kHz region, which also carries a lot of the speech and music information. Low-passing the logarithm of the signal and then converting back did better still but doesnâ€™t significantly remove the mains noise.


Of these simple filters, the best performing was a band-pass Butterworth filter with frequency response shown in Figure~\ref{fig:butterworth}. This filter is `maximally flat' within the band region, here 150Hz to 3kHz, and trails off outside of the band with slope dependent on the order of the filter, here of order 5. This still suffered from the presence of the higher mains harmonics. However, behind the remaining noise one could hear something distinctly speech-like or musical, just with very low intelligibility, you couldnâ€™t understand the speech but could recognise that someone was talking.


Note that we also replicated the Viterbi algorithm results from before with the photodiode, but only with the mains hum removed and high-passing above 100Hz, else the algorithm never selected the signal. Except for being over audible frequencies, there isnâ€™t much difference in the tracking once these filters are applied. \jam{Should I show photodiode Viterbi results?}

\begin{figure}%[H]
	\includegraphics[width=0.8\textwidth]{figures/butterworth_150_3000-cropped.pdf}
	\caption{Butterworth bandpass filter frequency response, green vertical lines show the band limits of 150Hz and 3kHz. Note the very flat response within the band, any amplitude beyond -3dB is significant attenuation.}
	\label{fig:butterworth}
\end{figure}

\subsection{logMMSE estimator}
% logMMSE

Speech enhancement for a noisy channel is a classic problem in signal processing. Hu~\&~Loizou~(2006)~\cite{SubjectiveComparison} compare various methods and find the best performing statistical technique to be the logMMSE (alt.\ MMSE-LSA) estimator which minimises the mean square error (MSE) of the log-spectral amplitude. This means that it takes the logarithm of the spectrum of the original signal and finds the fit (or estimate) that has the minimal MSE to that log-spectra.
% Use of the logarithm is a common technique in speech processing as it, somewhat surprisingly, does not significantly change the intelligibility to the human ear.


Applying an existing implementation of logMMSE\cite{logmmse} to the optical microphone recordings produces dramatically cleaner results. The time series and spectrum from before and after the logMMSE filter is applied are shown in Figures~\ref{fig:logMMSE_timeseries}~\&~\ref{fig:logMMSE_spectrum}. All of the mains harmonics are significantly attenuated. And further high-passing removes the low frequency curve beneath 100Hz.


There is varied success with passing music passed through the filters. Loud, rhythmic chords and drums are received well and remain recognisable, while thinner, airy flute and violin melodies struggle to be heard in the results. It is likely that the lower sounds have higher amplitude speaker oscillations and so pass through the optical microphone better.


However, speech intelligibility remains very low with the voice sounding mumbled and indistinct. Enhancement so far has removed most of the background sound, as evidenced by the near silence between words, but has not clarified the speech. There is a question here as to where the diction in the speech is lost, at the speaker-mirror coupling, at the photodiode reading, or if it is still there, just obscured in the noisy signal.

% The fringe counting problem of the detector, wherein multiple fringes passing over the array in a single speaker deflection artificially raises the frequency, was noticeable in the speech recordings when compared to the source audio. However, upon comparing injected pure tones, the increase appears to be minimal and inconsistent, at around 5Hz maximum difference. An simple explanation is that the speaker deflections are small compared to manual pressing on the optical table.
% % Visually it is impossible to confirm this for high frequencies, but it remains possible.

\begin{figure}%[H]
	\includegraphics[width=\textwidth]{figures/filter_timeseries_aa_melatos-cropped.pdf}
	\caption{Optical microphone recording of adult male voice (saying ``A cathode ...'') shown before (top) and after (bottom) logMMSE filter is applied, only one second of the one minute recording is shown. The bump at the start of the time series is the result of filtering a finite signal, and is expected.}
	\label{fig:logMMSE_timeseries}
\end{figure}

\begin{figure}%[H]
	\includegraphics[width=\textwidth]{figures/filter_spectrum_aa_melatos-cropped.pdf}
	\caption{Spectrum of optical microphone recording of adult male voice shown before (top) and after (bottom) logMMSE filter is applied, showing only up to 2kHz and a detail of the spectrum (limited to show only up to amplitude 2, while before filtering the 50Hz line has an amplitude of 40)}
	\label{fig:logMMSE_spectrum}
\end{figure}


\section{Future work}

A full model of the transfer function would detail the system starting from the voltage sent to the speaker and ending with the value recorded by the Pi, including any non-linearities in the speaker audio production, the speaker-mirror coupling, the separation-intensity relation, and the photodiode reading. Although we have the separation-intensity relation as non-linear for small motions, the other components of this full model are yet to be determined.


Theoretically, if we had the correct model, then signal recovery would only be limited by the SNR. We could also use long recordings of white noise to estimate a matched filter for the system.


For further speech enhancement, the optimal filter would involve a hidden-Markov-model trained to English phonemes. Alternatively, machine learning solutions also exist through-out the field.
% SEGAN?

% any other wild speculation?

\jam{should this be more broad a future work section?}


\section{Conclusions}

Using a Michelson interferometer, we able to successfully demonstrate the Viterbi algorithm recovering an injected signal. Just as is done is continuous gravitational wave searches. We are also able to play-back chordal or rhythmic music from an optical microphone (using the same interferometer), while recordings of simple speech are audible but unintelligible.

\newpage
\appendix

\section{Open-source code}
This project is implemented in python3\cite{python} inside of jupyter notebooks\cite{jupyter}\cite{ipython} and uses the packages of numpy\cite{numpy}, scipy\cite{scipy}, matplotlib\cite{matplotlib}, tqdm\cite{tqdm}, and logmmse\cite{logmmse}.

The current build can be found at:
\url{https://github.com/daccordeon/gravexplain}
% \begin{verbatim}
% README
% \end{verbatim}

% \newpage
\section{Intensity relation derivation}
\label{app:intensity_derivation}

We want the change in intensity, $\delta I$, at a point in the Michelson interference pattern, given a small change, $\delta d$, in the perpendicular path difference of the mirrors (or in the separation of one and virtual image of the other). The point is at angle $\theta$ on the screen above the central ray, noting circular symmetry. At this point, two rays meet, one from each mirror, with the total electric field (\jam{parallel to the screen?}) being $E_1(t) + E_2(t)$. Given an initial separation of $d$, the path difference between the mirrors is $2 d \cos{\theta}$ as the longer ray must travel to and from the further mirror, and both move up at the angle $\theta$ to meet at the screen.

\begin{align}
\label{eq:intensity_derivation}
    E_1(t) &= A e^{i (k L - \omega t)} \\
    E_2(t) &= A e^{i (k (L + 2 d \cos{\theta}) - \omega t)} \\
    I(t) &= \lvert A e^{i (k L - \omega t)} + A e^{i (k (L + 2 d \cos{\theta}) - \omega t)} \rvert^2
\end{align}

Collapse the phase difference to $\phi$ and expand the norm squared by expanding the complex exponentials. From there is it trigonometric manipulation to reach the result of intensity in terms of separation.

\begin{align}    
    I(t) &= A^2 \lvert e^{i (k L - \omega t)} + e^{i (k L + \phi - \omega t)} \rvert^2,\, \phi = 2 k d \cos{\theta} \\
    I(t) &= A^2 ((\cos{(k L - \omega t)} + \cos{(k L + \phi - \omega t)})^2 + (\sin{(k L - \omega t)} + \sin{(k L + \phi - \omega t)})^2) \\
    I(t) &= A^2 (1 + 2 \cos{(k L - \omega t)} \cos{(k L + \phi - \omega t)} + 1 + 2 \sin{(k L - \omega t)} \sin{(k L + \phi - \omega t)}) \\
    I(d) &= 2 A^2 (1 + \cos{\phi}),\, \phi = \frac{4 \pi d \cos{\theta}}{\lambda}
\end{align}

Then take derivatives and find that the intensity change is non-linear.

\begin{align}    
    \frac{\delta I}{\delta d} &= \frac{\delta I}{\delta \phi}\; \frac{\delta \phi}{\delta d}\\
    \frac{\delta I}{\delta\phi} &= - 2 A^2 \sin{\phi}\\
    \frac{\delta\phi}{\delta d} &= \frac{4 \pi \cos{\theta}}{\lambda}\\
    \therefore \frac{\delta I}{\delta d} &= \frac{- 8 \pi A^2 \cos{\theta}}{\lambda} \sin{(\frac{4 \pi \cos{\theta}}{\lambda} d)}
\end{align}

\section{The Viterbi Algorithm}
\label{app:viterbi}

To find the Viterbi path through a spectrogram (spectra over time), given an M x N grid of M frequency rows and N time columns and a rate limit for the change of frequency over time that we convert into the number of allowed rows we can move while stepping from each column to the next (this limit was $\pm 1$ row/column in our case). The path must start from the first column and end at the last, taking a single step in each column along the way. Each element in the grid is the norm of the Fourier component of a frequency at a time. These are normalised between $(0, 1)$ to use as multiplicative weights, i.e.\ the total weight of a path is the product of all weights along that path. In fact, we take the logarithm and so the sum of all weights to avoid underflow. The best path has the highest weight.


With the grid prepared, the Viterbi algorithm starts in the second column. In each iteration, the algorithm looks for the best path to each cell from the cells in the previous column, taking the greatest cumulative weight of those available, â€˜nearbyâ€™ cells (the value of which was discovered in the previous iteration).
For each cell in the current column, the algorithm notes this weight plus the cellâ€™s own weight, along with the row index of which cell in the previous column it came from.
Continuing like this until it reaches the end of the grid, the algorithm then looks for the greatest weight in the last column and retraces the indices of the steps it took until it reaches the start of the grid. That best path is the Viterbi path.


\section{Common changing frequency mistake}
\label{app:phase_gotcha}

We want to generate a sine wave that changes frequency over time so that the frequency at some time is given by a function $f(t)$. The common mistake is to just appeal to the standard form $\sin{(2 \pi f t)}$, where f would be a constant frequency, and write down $\sin{(2 \pi f(t) t)}$. However, accumulation of phase means that this produces a curve that looks very different to that desired. Instead, one should see that the standard form in fact says that for some $\sin{(F(t))}$ it is true that $\frac{dF}{dt}(t) = 2 \pi f(t)$, where $f(t)$ gives the frequency of $\sin{(F(t))}$ at time $t$. Therefore, the correct form for a wandering tone is $\sin{(\int{2 \pi f(t) dt})}$.

\section{Circuit design}
\label{app:circuit_diagram}
% schematic of breadboard and connections to pi
% https://www.circuit-diagram.org/editor/
% https://crcit.net/c/e397dcc2166943d69155f9dac1e27bce

Figure~\ref{fig:circuit_diagram} shows the photodiode circuit diagram, it is also available at \url{https://crcit.net/c/e397dcc2166943d69155f9dac1e27bce}

\begin{figure}%[H]
	\includegraphics[width=\textwidth]{figures/circuit_diagram_2.pdf}
	\caption{Circuit diagram for photodiode reading. Photodiode in reverse-bias over an op-amp, analog signal then passed through Sallen-Key anti-aliasing filter tuned to 16kHz, then into an analog-to-digital converter (ADC), thatâ€™s finally read by the special purpose input (SPI) pins of a Raspberry Pi}
	\label{fig:circuit_diagram}
\end{figure}



\begin{acknowledgments}
The authors are grateful to Jude Prezens, Alex Tolotchkoc, and Blake Molyneux for their technical advice and generous assistance throughout the project.
	
The authors are also grateful to Deeksha Beniwal, Sebastian Ng, and Craig Ingram for their advice and work in designing the interferometer. 

This research is supported by the Australian Research Council Centre of Excellence for Gravitational Wave Discovery (OzGrav) (project number CE170100004) and the Institute of Physics International Member Grant.

Travel during the project was supported by the Australian National University PhB Science  program.

\end{acknowledgments}


\bibliographystyle{myunsrt}
\bibliography{ifoDemoBib}

\end{document}
