{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"experiment_viterbi.ipynb\n",
    "James Gardner 2020\n",
    "ANU / Melbourne Uni\n",
    "\n",
    "applies viterbi analysis pipeline to experiment video of\n",
    "michelson interferometer with a mirror driven at a changing frequency\n",
    "takes signal as time series of intensity at the video's centre\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_spectrum(signal, fps, return_spectrum=False,\n",
    "                     produce_plot=False, out_plot_name='tmp.pdf', out_plot_title=''):\n",
    "    \"\"\"finds fourier spectrum of signal time series as numpy array,\n",
    "    has functionality to return and/or plot the sectrum (both default off),\n",
    "    built from code originally found in tracker_time_series.ipynb\n",
    "    \"\"\"   \n",
    "    signal_frames = len(signal)\n",
    "    # will drop two frames later, fps: frames per second\n",
    "    total_time = (signal_frames-2)/fps\n",
    "    t = np.linspace(0,total_time,signal_frames)\n",
    "    dt = t[1] - t[0]\n",
    "\n",
    "    yf = np.fft.fft(signal)\n",
    "    # normalised-absolute value of FT'd signal\n",
    "    nrm_abs_yf = 2/signal_frames*np.abs(yf)\n",
    "    # values at the centre of each frequency bin\n",
    "    freq_scale = np.fft.fftfreq(len(yf),dt)\n",
    "    # real signals are symmetric about 0 in frequency domain\n",
    "    freq_scale_positive = freq_scale[:signal_frames//2]\n",
    "    # frequency distribution values on positive side\n",
    "    freq_prob = nrm_abs_yf[:signal_frames//2]\n",
    "    \n",
    "    if produce_plot:\n",
    "        fig, (ax0,ax1) = plt.subplots(2,figsize=(14,14))\n",
    "        ax0.plot(t,signal)\n",
    "        ax0.set(title='signal: {}'.format(out_plot_title),ylabel='signal strength',xlabel='time, t')\n",
    "        # signal average value gives magnitude of frequency = 0 term\n",
    "        # simple fix is to drop first two bins, otherwise need to shift signal\n",
    "        ax1.plot(freq_scale_positive[2:],freq_prob[2:])\n",
    "        ax1.set(title='discrete FFT',ylabel='freq strength in signal',xlabel='frequency, f')\n",
    "        plt.savefig(out_plot_name,bbox_inches='tight')\n",
    "        plt.clf()\n",
    "    \n",
    "    if return_spectrum:\n",
    "        return freq_prob[2:], freq_scale_positive[2:]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_at_point(filename, point=None, return_series=False,\n",
    "                    produce_plot=False, out_plot_name='tmp.pdf'):\n",
    "    \"\"\"finds time series green-channel intensity at a point in the video,\n",
    "    has functionality to both return and plot series (both default off)\n",
    "    \"\"\"\n",
    "    # standard python3-openCV point capture\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    pbar = tqdm(total=total_frames-1)\n",
    "\n",
    "    point_intensity = []\n",
    "    # frame is numpy array of b,g,r values at each pixel\n",
    "    ret, frame = cap.read()\n",
    "    if point is None:\n",
    "        # default to centre of frame\n",
    "        point = tuple([int(i/2) for i in frame.shape[:2]])\n",
    "\n",
    "    while ret:\n",
    "        # green channel is the most important for greyscale intensity\n",
    "        # https://en.wikipedia.org/wiki/Relative_luminance        \n",
    "        # so approximate greyscale as just the green channel\n",
    "        point_intensity.append(frame[point][1])\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "    cap.release()\n",
    "\n",
    "    if produce_plot:\n",
    "        fourier_spectrum(point_intensity, fps, produce_plot=True,\n",
    "                         out_plot_name=out_plot_name, out_plot_title=filename)\n",
    "    if return_series:\n",
    "        return point_intensity, fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_pathfinder(grid, scanning_range=3):\n",
    "    \"\"\"find the highest scoring path through the grid, left-to-right,\n",
    "    as by the viterbi algorithm, with connections plus-minus the scanning_range;\n",
    "    returns score grid for best path to each node and a bitmap of the total best path\n",
    "    \"\"\"\n",
    "    # normalised grid, algorithm goal is to maximise product of values\n",
    "    ngrid  = grid/np.max(grid)\n",
    "    # logarithm avoids underflow, equvivalent to maximise sum of log of values\n",
    "    lngrid = np.log(ngrid)\n",
    "    \n",
    "    long_timesteps = grid.shape[1]\n",
    "\n",
    "    # keep track of running scores for best path to each node\n",
    "    score_grid  = np.copy(lngrid)\n",
    "    pathfinder_flag = len(lngrid[:,0])\n",
    "    # pathfinder stores the survivor paths, i.e. the previous best step\n",
    "    # to allow back-tracking to recover the best total path at the end\n",
    "    pathfinder = np.full(np.shape(lngrid), pathfinder_flag)\n",
    "    # pathfinder flag+1 for reaching the first, 0-index column        \n",
    "    pathfinder[:,0] = pathfinder_flag+1       \n",
    "\n",
    "    # implementation of the viterbi algorithm itself\n",
    "    # finding the best path to each node, through time\n",
    "    # see: https://www.youtube.com/watch?v=6JVqutwtzmo\n",
    "    for j in range(1,long_timesteps):\n",
    "        for i in range(len(score_grid[:,j])):\n",
    "            # index values for where to look relative to i in previous column\n",
    "            k_a = max(0, i-scanning_range) \n",
    "            k_b = min(len(score_grid[:,j-1])-1,\n",
    "                      i+scanning_range)\n",
    "            window = score_grid[:,j-1][k_a:k_b+1]\n",
    "            # find the best thing nearby in the previous column ...\n",
    "            window_score = np.max(window)\n",
    "            window_ref   = k_a+np.argmax(window)\n",
    "            # ... and take note of it, summing the log of values\n",
    "            score_grid[i][j] += window_score\n",
    "            pathfinder[i][j] = window_ref \n",
    "\n",
    "    # look at the very last column, and find the best total ending ...\n",
    "    best_score  = np.max(score_grid[:,-1])\n",
    "    best_end = np.argmax(score_grid[:,-1])\n",
    "    # ... and retrace its steps through the grid\n",
    "    best_path_back = np.full(long_timesteps,pathfinder_flag+2)\n",
    "    best_path_back[-1] = best_end\n",
    "    # best_path_back is the viterbi path, the highest scoring overall \n",
    "    # path_grid is the binary image of the viterbi path taken\n",
    "    path_grid = np.zeros(np.shape(ngrid))\n",
    "    tmp_path = pathfinder[best_end][-1]\n",
    "\n",
    "    for j in reversed(range(0,long_timesteps-1)):\n",
    "        path_grid[tmp_path][j] = 1\n",
    "        # take pathfinder value in current step and follow it backwards\n",
    "        best_path_back[j] = tmp_path    \n",
    "        tmp_path = pathfinder[tmp_path][j]\n",
    "\n",
    "    # make sure we got all the way home\n",
    "    # (that the retrace found the initial edge)\n",
    "    assert tmp_path == pathfinder_flag+1\n",
    "    \n",
    "    return score_grid, path_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inj_wandering_signal(duration=300, fps=16000,\n",
    "                         meander_amp=9, meander_decay=0.01, meander_freq=0.005,                     \n",
    "                         filetag='webcam', return_freq_series=False, save_to_csv=False,\n",
    "                         save_wav_recording=False, plot_wandering_signal = False):\n",
    "    \"\"\"creates wandering frequency, FM-modulated signal to test viteri analysis,\n",
    "    default arguments are for testing the webcam, else see below for photodiode arguments:\n",
    "    meander_amp, meander_decay, meander_freq = 300, 0.01, 0.01\n",
    "    filetag = 'podo'  \n",
    "    \"\"\"\n",
    "    # 5 minutes duration\n",
    "    long_timesteps = fps*duration\n",
    "\n",
    "    bin_time = np.linspace(0,300,long_timesteps)\n",
    "    # meander is the long scale change in the sine frequency\n",
    "    meander = lambda x: meander_amp*(\n",
    "        np.exp(-x*meander_decay)*np.sin(meander_freq*2*np.pi*x))\n",
    "\n",
    "    initial_frequency = 5\n",
    "    # initial_frequency = 440\n",
    "    wandering_freqs = initial_frequency + meander(bin_time)\n",
    "\n",
    "    big_n = bin_time.shape[0]\n",
    "    freq_series = np.zeros((100, 2))\n",
    "    freq_series[:, 0], freq_series[:, 1] = (bin_time[::big_n//99],\n",
    "                                      wandering_freqs[::big_n//99])\n",
    "    \n",
    "    if save_to_csv:\n",
    "        # careful, inj_wandering_webcam is the frequency, not the actual signal\n",
    "        np.savetxt('inj_wandering_{}.csv'.format(filetag), freq_series, delimiter=',')\n",
    "\n",
    "    # sin(2*pi*f*t)\n",
    "    # therefore sin(g(t)), 2*pi*f = dg/dt\n",
    "    # sin(2*pi*\\int{f(t)dt}) gives f = f(t)\n",
    "    # and cumsum is discrete \\int (integral)\n",
    "    # https://au.mathworks.com/matlabcentral/answers/217746-\n",
    "    # implementing-a-sine-wave-with-linearly-changing-frequency\n",
    "\n",
    "    inj_signal = np.sin(2*np.pi*np.cumsum(wandering_freqs)/fps)\n",
    "    if save_wav_recording:\n",
    "        # this is the signal to play (i.e. inject) into the interferometer\n",
    "        wavfile.write('inj_{}.wav'.format(filetag), int(fps), inj_signal)\n",
    "\n",
    "    if plot_wandering_signal:\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        plt.plot(bin_time, wandering_freqs)\n",
    "        # plt.xlim(0, 60)\n",
    "        plt.title('{} viterbi test: injected frequency versus time'.format(filetag))\n",
    "        plt.xlabel('time, t / s')\n",
    "        plt.ylabel('injected signal frequency, f / Hz')\n",
    "        plt.savefig('wandering_{}.pdf'.format(filetag))\n",
    "        plt.clf()\n",
    "        \n",
    "    if return_freq_series:\n",
    "        return freq_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointViterbi(object):\n",
    "    \"\"\"finds viterbi path through frequency spectrum measured at\n",
    "    centre point over time for changing driving frequency\n",
    "    \"\"\"      \n",
    "    def __init__(self,filename,long_timesteps=None,scanning_range=3):\n",
    "        # start by finding the signal to be split into bins\n",
    "        # no point specified, so series_at_point will choose the centre of the frame\n",
    "        long_signal, fps = series_at_point(filename,return_series=True)\n",
    "\n",
    "        total_frames = len(long_signal)\n",
    "        duration = total_frames/fps\n",
    "        if long_timesteps is None:\n",
    "            # for every minute, add an extra 20 long time bins\n",
    "            long_timesteps = int(20*duration/60)\n",
    "        # q,r = divmod(a,b) s.t. a = q*b+r\n",
    "        bin_frames, bin_remainder = divmod(total_frames,long_timesteps)\n",
    "        # bin_duration = bin_frames/fps\n",
    "        # acts as flag to stop short of the remainder, which is lost\n",
    "        bin_last = total_frames - bin_remainder\n",
    "        # always has long_timesteps number of chunks\n",
    "        bin_signals = [long_signal[i: i+bin_frames] for i in range(0, bin_last, bin_frames)]\n",
    "\n",
    "        # creating the signal grid\n",
    "        # positive side of the fourier spectrum will have half bin_frames\n",
    "        # minus 2 from cutting out the average value, frequency = 0, signal\n",
    "        grid_frames = bin_frames//2-2\n",
    "        grid = np.zeros((grid_frames,long_timesteps))\n",
    "\n",
    "        for i,signal in enumerate(bin_signals):\n",
    "            # columns are each spectrum, rows are frequency through time\n",
    "            col, freq_scale_cut = fourier_spectrum(signal, fps, return_spectrum=True)\n",
    "            grid[:,i] = col\n",
    "            \n",
    "        path_grid = viterbi_pathfinder(grid, scanning_range)[1]\n",
    "        \n",
    "        ngrid = grid/np.max(grid)\n",
    "        self.ngrid = ngrid\n",
    "        self.path_grid = path_grid\n",
    "        # _plot_bundle not meant to be accessed other than for plotting\n",
    "        self._plot_bundle = filename, long_timesteps, duration, grid_frames, freq_scale_cut \n",
    "\n",
    "    def plot(self, filetag=None, x_tick_skip=10, y_tick_skip=8):\n",
    "        \"\"\"saves plots of the signal grid and the recovered viterbi path,\n",
    "        filetag is added to standardised plot filenames\n",
    "        \"\"\"\n",
    "        # mirror _plot_bundle assignment above\n",
    "        filename, long_timesteps, duration, grid_frames, freq_scale_cut = self._plot_bundle\n",
    "        \n",
    "        if filetag is None:\n",
    "            c0, c1 = filename.find('expt_'), filename.find('.mp4')\n",
    "            filetag = filename[c0+len('expt_'):c1]         \n",
    "\n",
    "        x_tick_vals = np.arange(0, duration, 30)\n",
    "        x_ticks_0 = x_tick_vals*long_timesteps/duration\n",
    "        x_tick_labels_0 = x_tick_vals.astype('int')\n",
    "\n",
    "        y_tick_vals = np.arange(1, 15, 2)\n",
    "        y_ticks_0 = (y_tick_vals-freq_scale_cut[0])*len(freq_scale_cut)/(\n",
    "            freq_scale_cut[-1]-freq_scale_cut[0])\n",
    "        y_tick_labels_0 = ['{:.1f}'.format(i) for i in y_tick_vals]\n",
    "\n",
    "        pg = (self.path_grid)\n",
    "        pgp = np.argwhere(pg == 1)\n",
    "        pgp[:,[0,1]] = pgp[:,[1,0]]\n",
    "        pgp = pgp[pgp[:,0].argsort()]\n",
    "        inj_signal = inj_wandering_signal(return_freq_series=True)[:,1][1:]\n",
    "\n",
    "        plt.plot(figsize=(14,7))\n",
    "        plt.imshow(self.ngrid, cmap='viridis')\n",
    "        plt.plot(pgp[:,1], 'x', color='azure', ms=2)\n",
    "        plt.plot(np.searchsorted(freq_scale_cut, inj_signal), '.', color='fuchsia', ms=2) \n",
    "        plt.xticks(x_ticks_0, x_tick_labels_0)\n",
    "        plt.yticks(y_ticks_0, y_tick_labels_0)\n",
    "        plt.ylabel('frequency, f / Hz')\n",
    "        plt.xlabel('time, t / s')\n",
    "        plt.gca().invert_yaxis()\n",
    "\n",
    "        plt.savefig('expt_overlay_2_{}.pdf'.format(filetag), bbox_inches='tight')\n",
    "        plt.clf()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old methods to test the video and produce plots\n",
    "filename = 'expt_4_0209.mp4'\n",
    "filetag = filename[:-4]\n",
    "\n",
    "cap = cv2.VideoCapture(filename)\n",
    "ret, frame = cap.read()\n",
    "cv2.imwrite('tmp_webcam_still.png',frame)\n",
    "cap.release()\n",
    "\n",
    "# plt.imshow(frame)\n",
    "plt.plot(230, 240, marker='o', markersize=5, color=\"red\")\n",
    "plt.imshow(plt.imread('tmp_webcam_still.png'))\n",
    "plt.axis('off')\n",
    "plt.savefig('webcam_still_0_{}.pdf'.format(filename), bbox_inches = 'tight')\n",
    "plt.clf()\n",
    "os.remove('tmp_webcam_still.png')\n",
    "\n",
    "signal, fps = series_at_point(filename, point=(230,240), return_series=True)\n",
    "freq_prob, freq_scale = fourier_spectrum(signal, fps, return_spectrum=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.plot(freq_scale, freq_prob)\n",
    "ax.set(xlabel='frequency, f / Hz', ylabel='Fourier amplitude', xlim=(0, 15), ylim=(0, None))\n",
    "ax.xaxis.set_ticks(np.arange(0, 16, 2))\n",
    "ax.xaxis.set_ticklabels(['{:.0f}'.format(i) for i in np.arange(0, 16, 2)])\n",
    "ax.xaxis.set_tick_params(labelsize=26)\n",
    "ax.xaxis.label.set_size(26)\n",
    "ax.yaxis.set_tick_params(labelsize=26)\n",
    "ax.yaxis.label.set_size(26)\n",
    "plt.grid()\n",
    "plt.savefig('webcam_spectrum_{}.pdf'.format(filetag), bbox_inches = 'tight')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding FWHM of the webcam spectrum\n",
    "i0 = np.searchsorted(freq_scale,2.05)\n",
    "i1 = np.searchsorted(freq_scale,2.15)\n",
    "xx = freq_scale[i0:i1]\n",
    "yy = freq_prob[i0:i1]\n",
    "hm = yy[3]/2\n",
    "\n",
    "from scipy import interpolate\n",
    "f = interpolate.interp1d(xx, yy)\n",
    "xnew = np.linspace(xx.min(), xx.max(), 100)\n",
    "ynew = f(xnew)\n",
    "\n",
    "f1 = interpolate.interp1d(yy[1:3], xx[1:3])\n",
    "f2 = interpolate.interp1d(yy[3:5], xx[3:5])\n",
    "x1, x2 = f1(hm), f2(hm)\n",
    "fw = x2 - x1\n",
    "print(\"FW\", fw, \"at HM\", hm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,7))\n",
    "# ax.plot(xx, yy, 'k,')\n",
    "ax.plot(xx, yy, '*', xnew, ynew, 'g-')\n",
    "ax.set(xlabel='frequency, f / Hz', ylabel='Fourier amplitude')\n",
    "ax.set_ylim([0,None])\n",
    "\n",
    "ax.plot(xx, np.full(xx.shape, hm), 'r')\n",
    "\n",
    "ax.axvline(x=x1)\n",
    "ax.axvline(x=x2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv = PointViterbi('expt_viterbi_test_webcam.mp4', scanning_range=1)\n",
    "pv.plot()\n",
    "\n",
    "filename, long_timesteps, duration, grid_frames, freq_scale_cut = pv._plot_bundle\n",
    "path_ind = np.argwhere(pv.path_grid == 1)\n",
    "sort_ind = np.argsort(path_ind[:,1])\n",
    "sorted_path_ind = path_ind[sort_ind][:,0]\n",
    "recovered_frequencies = freq_scale_cut[sorted_path_ind]\n",
    "\n",
    "injected_frequencies = inj_wandering_signal(return_freq_series=True)[:,1][1:-1]\n",
    "\n",
    "rms_frac_error = (1/len(injected_frequencies)*\n",
    "                  np.sum((injected_frequencies - recovered_frequencies)**2/\n",
    "                         (injected_frequencies)**2))**(1/2)\n",
    "print('RMS fractional error for Viterbi path against injected signal: {:.3f}'.format(rms_frac_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# as in main.py\n",
    "PVobj = PointViterbi('expt_viterbi_test_webcam.mp4', scanning_range=1)\n",
    "PVobj.plot()\n",
    "\n",
    "filename, long_timesteps, duration, grid_frames, freq_scale_cut = PVobj._plot_bundle\n",
    "\n",
    "# checks\n",
    "print(freq_scale_cut.shape)\n",
    "print(freq_scale_cut)\n",
    "print(15/len(freq_scale_cut))\n",
    "print(freq_scale_cut[3]-freq_scale_cut[2])\n",
    "\n",
    "for i in range(len(freq_scale_cut)-1):\n",
    "    print(freq_scale_cut[i+1]-freq_scale_cut[i])    \n",
    "\n",
    "print(duration/long_timesteps, 0.33712121212121215/3.0144781144781145)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'expt_viterbi_test_webcam.mp4'\n",
    "\n",
    "long_signal, fps = series_at_point(filename, return_series=True)\n",
    "freq_prob, freq_scale = fourier_spectrum(long_signal, fps, return_spectrum=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.plot(freq_scale, freq_prob)\n",
    "ax.set(xlabel='frequency, f / Hz', ylabel='Fourier amplitude', xlim=(0, 15), ylim=(0, None))\n",
    "ax.xaxis.set_ticks(np.arange(0, 16, 2))\n",
    "ax.xaxis.set_ticklabels(['{:.0f}'.format(i) for i in np.arange(0, 16, 2)])\n",
    "ax.xaxis.set_tick_params(labelsize=26)\n",
    "ax.xaxis.label.set_size(26)\n",
    "ax.yaxis.set_tick_params(labelsize=26)\n",
    "ax.yaxis.label.set_size(26)\n",
    "plt.grid()\n",
    "plt.savefig('viterbi_comparison_entire_spectrum_{}.pdf'.format(filetag), bbox_inches = 'tight')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
