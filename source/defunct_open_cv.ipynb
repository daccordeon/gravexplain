{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"open_cv.ipynb\n",
    "James Gardner 2019\n",
    "ANU / Melbourne Uni\n",
    "\n",
    "various auxillary python3-openCV functions\n",
    "all related to previous versions of experiment_viterbi,\n",
    "as well as manual calls to series_at_point, left out for script\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_spectrum(signal, fps, return_spectrum=False,\n",
    "                     produce_plot=False, out_plot_name='tmp.pdf', out_plot_title=''):\n",
    "    \"\"\"finds fourier spectrum of signal time series as numpy array,\n",
    "    has functionality to return and/or plot the sectrum (both default off),\n",
    "    built from code originally found in tracker_time_series.ipynb\n",
    "    \"\"\"   \n",
    "    signal_frames = len(signal)\n",
    "    # will drop two frames later, fps: frames per second\n",
    "    total_time = (signal_frames-2)/fps\n",
    "    t = np.linspace(0,total_time,signal_frames)\n",
    "    dt = t[1] - t[0]\n",
    "\n",
    "    yf = np.fft.fft(signal)\n",
    "    # normalised-absolute value of FT'd signal\n",
    "    nrm_abs_yf = 2/signal_frames*np.abs(yf)\n",
    "    # values at the centre of each frequency bin\n",
    "    freq_scale = np.fft.fftfreq(len(yf),dt)\n",
    "    # real signals are symmetric about 0 in frequency domain\n",
    "    freq_scale_positive = freq_scale[:signal_frames//2]\n",
    "    # frequency distribution values on positive side\n",
    "    freq_prob = nrm_abs_yf[:signal_frames//2]\n",
    "    \n",
    "    if produce_plot:\n",
    "        fig, (ax0,ax1) = plt.subplots(2,figsize=(14,14))\n",
    "        ax0.plot(t,signal)\n",
    "        ax0.set(title='signal: {}'.format(out_plot_title),ylabel='signal strength',xlabel='time, t')\n",
    "        # signal average value gives magnitude of frequency = 0 term\n",
    "        # simple fix is to drop first two bins, otherwise need to shift signal\n",
    "        ax1.plot(freq_scale_positive[2:],freq_prob[2:])\n",
    "        ax1.set(title='discrete FFT',ylabel='freq strength in signal',xlabel='frequency, f')\n",
    "        plt.savefig(out_plot_name,bbox_inches='tight')\n",
    "        plt.clf()\n",
    "    \n",
    "    if return_spectrum:\n",
    "        return freq_prob[2:], freq_scale_positive[2:]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_at_point(filename, point=None, return_series=False,\n",
    "                    produce_plot=False, out_plot_name='tmp.pdf'):\n",
    "    \"\"\"finds time series green-channel intensity at a point in the video,\n",
    "    has functionality to both return and plot series (both default off)\n",
    "    \"\"\"\n",
    "    # standard python3-openCV point capture\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    pbar = tqdm(total=total_frames-1)\n",
    "\n",
    "    point_intensity = []\n",
    "    # frame is numpy array of b,g,r values at each pixel\n",
    "    ret, frame = cap.read()\n",
    "    if point is None:\n",
    "        # default to centre of frame\n",
    "        point = tuple([int(i/2) for i in frame.shape[:2]])\n",
    "\n",
    "    while ret:\n",
    "        # green channel is the most important for greyscale intensity\n",
    "        # https://en.wikipedia.org/wiki/Relative_luminance        \n",
    "        # so approximate greyscale as just the green channel\n",
    "        point_intensity.append(frame[point][1])\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "    cap.release()\n",
    "\n",
    "    if produce_plot:\n",
    "        fourier_spectrum(point_intensity, fps, produce_plot=True,\n",
    "                         out_plot_name=out_plot_name, out_plot_title=filename)\n",
    "    if return_series:\n",
    "        return point_intensity, fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoom(frame,r=0.5):\n",
    "    \"\"\"resizes frame while maintaining aspect ratio\"\"\"\n",
    "    rheight = int(frame.shape[0]*r)\n",
    "    rwidth  = int(frame.shape[1]*r)\n",
    "    # caution: order of width, height in resize call\n",
    "    return cv2.resize(frame,(rwidth,rheight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_tracker(filename,p0=None,ring_centre=None,out_filename='tmp.pdf'):\n",
    "    \"\"\"displays tracked point/s, saves fourier spectrum of primary point\"\"\"\n",
    "    # openCV image tracking tutorial\n",
    "    # https://opencv-python-tutroals.readthedocs.io/en/latest/\n",
    "    # py_tutorials/py_video/py_lucas_kanade/py_lucas_kanade.html\n",
    "    # https://stackoverqflow.com/questions/43063320/cv2-calcopticalflowpyrlk-adding-new-points\n",
    "\n",
    "    # cap = cv2.VideoCapture('noisy_tracking_test.mp4')\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    pbar = tqdm(total=total_frames-1)\n",
    "\n",
    "    # Parameters for lucas kanade optical flow\n",
    "    lk_params = dict( winSize  = (15,15),\n",
    "                      maxLevel = 2,\n",
    "                      criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "    # Create some random colors\n",
    "    color = np.random.randint(0,255,(100,3))\n",
    "\n",
    "    # Take first frame and find corners in it\n",
    "    ret, old_frame = cap.read()\n",
    "    old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # y, x; misnomer, set to frame centre\n",
    "    if ring_centre is None:\n",
    "        ring_centre = tuple([int(i/2) for i in old_frame.shape[:2]])\n",
    "    # 280, 355 #expt_0\n",
    "    # 455, 940 #expt_1,2,3\n",
    "\n",
    "    if p0 is None:\n",
    "        p0 = ring_centre\n",
    "        \n",
    "    p0 = np.array([list(p0)]).astype('float32')\n",
    "\n",
    "    # # params for ShiTomasi corner detection,\n",
    "    # feature_params = dict( maxCorners = 100,\n",
    "    #                        qualityLevel = 0.3,\n",
    "    #                        minDistance = 7,\n",
    "    #                        blockSize = 7 )\n",
    "    # p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "\n",
    "    # use pinta to get values for selected points\n",
    "    # tracking_test\n",
    "    # p0 = np.array([[1093,548],[1226,544],[1344,547],[1439,553]],np.float32)\n",
    "    # expt_0: 280,355\n",
    "    # p0 = np.array([[215,275]]).astype('float32')\n",
    "    # expt_1: 453,943 <-centres\n",
    "    # p0 = np.array([[735,455]]).astype('float32')\n",
    "    # expt_2: 453,946\n",
    "    # p0 = np.array([[720,450]]).astype('float32')\n",
    "    # expt_3: 458,938\n",
    "    # p0 = np.array([[734,450]]).astype('float32')\n",
    "\n",
    "    tracked_points = []\n",
    "    # print(p0)\n",
    "    # 427 175 , 401 187\n",
    "    # p0 = np.array([[[427,175]],[[401,187]]])\n",
    "\n",
    "    # Create a mask image for drawing purposes\n",
    "    mask = np.zeros_like(old_frame)\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    after_first = False\n",
    "\n",
    "    while ret:\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # calculate optical flow\n",
    "        p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "\n",
    "        # Select good points\n",
    "        #print(p1,p0,st,err)\n",
    "        good_new = p1#[st==1]\n",
    "        good_old = p0#[st==1]\n",
    "\n",
    "        # draw the tracks\n",
    "        for i,(new,old) in enumerate(zip(good_new,good_old)):\n",
    "            a,b = new.ravel()\n",
    "            c,d = old.ravel()\n",
    "            mask = cv2.line(mask, (a,b),(c,d), color[i].tolist(), 2)\n",
    "            frame = cv2.circle(frame,(a,b),5,color[i].tolist(),-1)\n",
    "        img = cv2.add(frame,mask)\n",
    "\n",
    "        cv2.imshow('title',zoom(img))\n",
    "        if cv2.waitKey(15) & 0xff == ord('q'):\n",
    "            break\n",
    "\n",
    "        # Now update the previous frame and previous points\n",
    "        old_gray = frame_gray.copy()\n",
    "        p0 = good_new.reshape(-1,1,2)\n",
    "        pbar.update(1)\n",
    "\n",
    "        if after_first:\n",
    "            tracked_points.append([p[0] for p in p1])    \n",
    "        else:\n",
    "            after_first = True\n",
    "\n",
    "        ret,frame = cap.read()\n",
    "\n",
    "    tracked_points = np.array(tracked_points)\n",
    "    pbar.close()\n",
    "    cv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "\n",
    "    # ring_centre = y, x\n",
    "    tracker_0 = tracked_points#[:,:,0]\n",
    "    dist_to_ring_centre = lambda y, x: ((y-ring_centre[0])**2+(x-ring_centre[1])**2)**0.5\n",
    "    tracker_0_radius = np.array([dist_to_ring_centre(*p[0]) for p in tracker_0])\n",
    "\n",
    "    fourier_plot(tracker_0_radius, fps, return_spectrum=False,\n",
    "                 out_plot_name=out_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mock_rings(filename='green_rings.mp4'):\n",
    "    \"\"\"creates video of mock interference rings\"\"\"\n",
    "    # maximum when 2*d*cos(theta) = n*lambda\n",
    "    # cos[theta] = n*(lambda/(2*d[t]))\n",
    "    # phys_arg is ultimately time varying, lambda/(2*d[t])\n",
    "    phys_arg = 0.019\n",
    "    total_rings = int(1/phys_arg)\n",
    "    angles = np.arccos([n*phys_arg for n in range(1,total_rings+1)])\n",
    "\n",
    "    # pretend that source is 1 away from centre of screen of height 2\n",
    "    # tan(theta) gives then gives the fractional radius\n",
    "    frac_radii = np.tan(angles)\n",
    "    frac_radii = frac_radii[frac_radii < 1]\n",
    "\n",
    "    # write video of rings\n",
    "    fps = 30\n",
    "    duration = 20\n",
    "    total_frames = 30*5\n",
    "    # caution: array[1], array[0]\n",
    "    frame_size = 512, 512\n",
    "    frame_array_size = 512, 512, 3\n",
    "\n",
    "    out = cv2.VideoWriter(filename,cv2.VideoWriter_fourcc(*'mp4v'),fps,frame_size)\n",
    "\n",
    "    for i in tqdm(range(total_frames)):\n",
    "        out_frame = np.full(frame_array_size, 255).astype('uint8')\n",
    "\n",
    "        # cv.Circle(img, center, radius, color, thickness=1) \n",
    "        circle_pos_height = int(frame_size[1]/2)\n",
    "        circle_pos_width  = int(frame_size[0]/2)\n",
    "        min_frame_dim = int(np.min(frame_size)/2)\n",
    "        oscillation_amp = 5\n",
    "        oscillation_speed = i/(2*np.pi)\n",
    "\n",
    "        for r in frac_radii:\n",
    "            circle_radius = int(r*min_frame_dim + oscillation_amp*np.sin(oscillation_speed))\n",
    "            cv2.circle(out_frame,(circle_pos_width,circle_pos_height),circle_radius,[0,255,0]) \n",
    "\n",
    "        out.write(out_frame)\n",
    "    \n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(filename='green_rings.mp4',noise_level=10):\n",
    "    \"\"\"adds noise to a .mp4 video, saves separately\"\"\"\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "    total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)    \n",
    "    pbar = tqdm(total=total_frames-1)\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    # width, height\n",
    "    frame_size = frame.shape[0:2][::-1]\n",
    "    out = cv2.VideoWriter('noisy_{}'.format(filename),cv2.VideoWriter_fourcc(*'mp4v'),fps,frame_size)\n",
    "\n",
    "    while ret:\n",
    "        noisy_frame = np.random.normal(0,noise_level,frame.shape).astype('uint8')\n",
    "        out_frame = cv2.add(frame,noisy_frame)\n",
    "        out.write(np.uint8(out_frame))\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "    cap.release()\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# track inner ring by manual point selection\n",
    "expt_nums = '4_0209','4_0580','4_0581','4_1099','4_2014'\n",
    "points = (200,250),(230,270),(240,250),(220,310),(230,320)\n",
    "\n",
    "for i in range(len(expt_nums)):\n",
    "    series_at_point('expt_{}.mp4'.format(expt_nums[i]), points[i],\n",
    "                    produce_plot=True, out_plot_name='expt_{}.pdf'.format(expt_nums[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_tracker('expt_5_slow.mp4',out_filename='expt_cv_tracked_5_slow.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_rings()\n",
    "add_noise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
