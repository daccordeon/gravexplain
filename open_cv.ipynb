{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"open_cv.ipynb\n",
    "James Gardner 2019\n",
    "\n",
    "various basic python3-openCV things\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoom(frame,r=0.5):\n",
    "    \"\"\"resizes frame while maintaining aspect ratio\"\"\"\n",
    "    rheight = int(frame.shape[0]*r)\n",
    "    rwidth  = int(frame.shape[1]*r)\n",
    "    # caution: order of width, height in resize call\n",
    "    return cv2.resize(frame,(rwidth,rheight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_plot(signal, fps, out_plot_name, out_plot_title=''):\n",
    "    \"\"\"plots fourier of time series\"\"\"\n",
    "    # implementation from tracker_time_series\n",
    "    # after_first loses a frame\n",
    "    signal_frames = len(signal)\n",
    "    total_time = (signal_frames-2)/fps\n",
    "    t = np.linspace(0,total_time,signal_frames)\n",
    "    dt = t[1] - t[0]\n",
    "\n",
    "    yf = np.fft.fft(signal)\n",
    "    # normalised-absolute value of FT'd signal\n",
    "    nrm_abs_yf = 2/signal_frames*np.abs(yf)\n",
    "    freq_scale = np.fft.fftfreq(len(yf),dt)\n",
    "    # np.fft.fftfreq outputs 0 to +inf then -inf to 0, so :N//2 gets +ve side; wild!\n",
    "    freq_prob = nrm_abs_yf[:signal_frames//2]\n",
    "\n",
    "    fig, (ax0,ax1) = plt.subplots(2,figsize=(14,14))\n",
    "    ax0.plot(t,signal)\n",
    "    ax0.set(title='signal: {}'.format(out_plot_title),ylabel='signal strength',xlabel='time, t')\n",
    "    # filter out the average value gives magnitude of zero freq term\n",
    "    ax1.plot(freq_scale[:signal_frames//2][2:],freq_prob[2:])\n",
    "    ax1.set(title='discrete FFT',ylabel='freq strength in signal',xlabel='frequency, f')\n",
    "    # REMEMBER TO CHANGE OUT FILENAME\n",
    "    plt.savefig(out_plot_name,bbox_inches='tight')\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_at_point(expt_num, point=None):\n",
    "    \"\"\"green channel intensity at point in the interference pattern\n",
    "    also plots time series and spectrum thereof\n",
    "    aka: run_dog_run\"\"\"\n",
    "    cap = cv2.VideoCapture('expt_{}.mp4'.format(expt_num))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    pbar = tqdm(total=total_frames-1)\n",
    "\n",
    "    centre_intensity = []\n",
    "    ret, frame = cap.read()\n",
    "    # default to centre of frame\n",
    "    if point is None:\n",
    "        point = tuple([int(i/2) for i in frame.shape[:2]])\n",
    "\n",
    "    while ret:\n",
    "        # centre time series\n",
    "        # use green channel since it has the greatest weight anyway\n",
    "        # https://en.wikipedia.org/wiki/Relative_luminance\n",
    "        centre_intensity.append(frame[point][1])\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    fourier_plot(centre_intensity, fps, 'expt_{}_centre.pdf'.format(expt_num), expt_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# track manually found first ring points\n",
    "expt_nums = '4_0209','4_0580','4_0581','4_1099','4_2014'\n",
    "points = (200,250),(230,270),(240,250),(220,310),(230,320)\n",
    "# zexpt_0: y, x = 280, 355\n",
    "\n",
    "for i in range(len(expt_nums)):\n",
    "    series_at_point(expt_nums[i], points[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"tracks points in video\"\"\"\n",
    "# openCV image tracking tutorial\n",
    "# https://opencv-python-tutroals.readthedocs.io/en/latest/\n",
    "# py_tutorials/py_video/py_lucas_kanade/py_lucas_kanade.html\n",
    "# https://stackoverqflow.com/questions/43063320/cv2-calcopticalflowpyrlk-adding-new-points\n",
    "\n",
    "# cap = cv2.VideoCapture('noisy_tracking_test.mp4')\n",
    "cap = cv2.VideoCapture('expt_1_shake.mp4')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "pbar = tqdm(total=total_frames-1)\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Create some random colors\n",
    "color = np.random.randint(0,255,(100,3))\n",
    "\n",
    "# Take first frame and find corners in it\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# # params for ShiTomasi corner detection,\n",
    "# feature_params = dict( maxCorners = 100,\n",
    "#                        qualityLevel = 0.3,\n",
    "#                        minDistance = 7,\n",
    "#                        blockSize = 7 )\n",
    "# p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "\n",
    "# use pinta to get values for selected points\n",
    "# tracking_test\n",
    "# p0 = np.array([[1093,548],[1226,544],[1344,547],[1439,553]],np.float32)\n",
    "# expt_0: 280,355\n",
    "# p0 = np.array([[215,275]]).astype('float32')\n",
    "# expt_1: 453,943 <-centres\n",
    "p0 = np.array([[735,455]]).astype('float32')\n",
    "# expt_2: 453,946\n",
    "# p0 = np.array([[720,450]]).astype('float32')\n",
    "# expt_3: 458,938\n",
    "# p0 = np.array([[734,450]]).astype('float32')\n",
    "\n",
    "# y, x\n",
    "# ring_centre = 280, 355 #expt_0\n",
    "ring_centre = 455, 940 #expt_1,2,3\n",
    "\n",
    "tracked_points = []\n",
    "# print(p0)\n",
    "# 427 175 , 401 187\n",
    "# p0 = np.array([[[427,175]],[[401,187]]])\n",
    "\n",
    "# Create a mask image for drawing purposes\n",
    "mask = np.zeros_like(old_frame)\n",
    "ret, frame = cap.read()\n",
    "\n",
    "after_first = False\n",
    "\n",
    "while ret:\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    # calculate optical flow\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "\n",
    "    # Select good points\n",
    "    #print(p1,p0,st,err)\n",
    "    good_new = p1#[st==1]\n",
    "    good_old = p0#[st==1]\n",
    "\n",
    "    # draw the tracks\n",
    "    for i,(new,old) in enumerate(zip(good_new,good_old)):\n",
    "        a,b = new.ravel()\n",
    "        c,d = old.ravel()\n",
    "        mask = cv2.line(mask, (a,b),(c,d), color[i].tolist(), 2)\n",
    "        frame = cv2.circle(frame,(a,b),5,color[i].tolist(),-1)\n",
    "    img = cv2.add(frame,mask)\n",
    "\n",
    "    #cv2.imshow('title',zoom(img))\n",
    "    #if cv2.waitKey(15) & 0xff == ord('q'):\n",
    "    #    break\n",
    "\n",
    "    # Now update the previous frame and previous points\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1,1,2)\n",
    "    pbar.update(1)\n",
    "    \n",
    "    if after_first:\n",
    "        tracked_points.append([p[0] for p in p1])    \n",
    "    else:\n",
    "        after_first = True\n",
    "    \n",
    "    ret,frame = cap.read()\n",
    "\n",
    "tracked_points = np.array(tracked_points)\n",
    "pbar.close()\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "\n",
    "# ring_centre = y, x\n",
    "tracker_0 = tracked_points#[:,:,0]\n",
    "dist_to_ring_centre = lambda y, x: ((y-ring_centre[0])**2+(x-ring_centre[1])**2)**0.5\n",
    "tracker_0_radius = np.array([dist_to_ring_centre(*p[0]) for p in tracker_0])\n",
    "\n",
    "fourier_plot(tracker_0_radius, fps, 'expt_1.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"save a zoomed version of the video\"\"\"\n",
    "cap = cv2.VideoCapture('expt_0.mp4')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frame_count = 0\n",
    "pbar = tqdm(total=total_frames)\n",
    "\n",
    "# width: 600-1400, height: 0-550\n",
    "ret, frame = cap.read()\n",
    "zframe = frame[0:550,600:1400]\n",
    "\n",
    "# width, height\n",
    "frame_size = zframe.shape[0:2][::-1]\n",
    "\n",
    "out = cv2.VideoWriter('zexpt_0.mp4',cv2.VideoWriter_fourcc(*'mp4v'),fps,frame_size)\n",
    "\n",
    "while ret:\n",
    "    zframe = frame[0:550,600:1400]    \n",
    "    out.write(np.uint8(zframe))    \n",
    "   \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    frame_count += 1\n",
    "    pbar.update(1)\n",
    "\n",
    "pbar.close()\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"creates mock rings\"\"\"\n",
    "# https://www.niser.ac.in/sps/sites/default/files/basic_page/Michelson%20Interferometer_P744%20-%20Optics.pdf\n",
    "# maximum when 2*d*cos(theta) = n*lambda\n",
    "# cos[theta] = n*(lambda/(2*d[t]))\n",
    "# phys_arg is ultimately time varying, lambda/(2*d[t])\n",
    "phys_arg = 0.019\n",
    "total_rings = int(1/phys_arg)\n",
    "angles = np.arccos([n*phys_arg for n in range(1,total_rings+1)])\n",
    "# print(angles*180/np.pi)\n",
    "\n",
    "# pretend that source is 1 away from centre of screen of height 2\n",
    "# tan(theta) gives then gives the fractional radius\n",
    "frac_radii = np.tan(angles)\n",
    "frac_radii = frac_radii[frac_radii < 1]\n",
    "# print(frac_radii)\n",
    "\n",
    "# write video of rings\n",
    "fps = 30\n",
    "duration = 20\n",
    "total_frames = 30*5\n",
    "# caution: array[1], array[0]\n",
    "frame_size = 512, 512\n",
    "frame_array_size = 512, 512, 3\n",
    "\n",
    "out = cv2.VideoWriter('green_rings.mp4',cv2.VideoWriter_fourcc(*'mp4v'),fps,frame_size)\n",
    "\n",
    "for i in tqdm(range(total_frames)):\n",
    "    out_frame = np.full(frame_array_size, 255).astype('uint8')\n",
    "    #out_frame[:,i] = [255,255,255]\n",
    "    #out_frame = np.uint8(cv2.add(frameA,frameB))\n",
    "\n",
    "    # cv.Circle(img, center, radius, color, thickness=1) \n",
    "    circle_pos_height = int(frame_size[1]/2)\n",
    "    circle_pos_width  = int(frame_size[0]/2)\n",
    "    min_frame_dim = int(np.min(frame_size)/2)\n",
    "    oscillation_amp = 5\n",
    "    oscillation_speed = i/(2*np.pi)\n",
    "    \n",
    "    for r in frac_radii:\n",
    "        circle_radius = int(r*min_frame_dim + oscillation_amp*np.sin(oscillation_speed))\n",
    "        cv2.circle(out_frame,(circle_pos_width,circle_pos_height),circle_radius,[0,255,0]) \n",
    "    \n",
    "    #cv2.imshow('title',out_frame)\n",
    "    #if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "    #    break\n",
    "    \n",
    "    out.write(out_frame)\n",
    "\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"adds noise to a video\"\"\"\n",
    "cap = cv2.VideoCapture('green_rings.mp4')\n",
    "total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "pbar = tqdm(total=total_frames-1)\n",
    "\n",
    "ret, frame = cap.read()\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "# width, height\n",
    "frame_size = frame.shape[0:2][::-1]\n",
    "\n",
    "out = cv2.VideoWriter('noisy_green_rings.mp4',cv2.VideoWriter_fourcc(*'mp4v'),fps,frame_size)\n",
    "\n",
    "while ret:\n",
    "    \n",
    "    #out_frame = cv2.flip(frame,1)\n",
    "    noise_level = 10\n",
    "    noisy_frame = np.random.normal(0,noise_level,frame.shape).astype('uint8')\n",
    "    out_frame = cv2.add(frame,noisy_frame)\n",
    "    #out_frame = cv2.add(frame,frame*noisy_frame)\n",
    "    #cv2.normalize(noisy_frame, noisy_frame, 0, 255, cv2.NORM_MINMAX, dtype=-1)\n",
    "    #noisy_image = noisy_image.astype(np.uint8)\n",
    "    #out_frame[out_frame < 0] = 0\n",
    "    #out_frame[out_frame > 255] = 255\n",
    "    out.write(np.uint8(out_frame))\n",
    "    \n",
    "    #cv2.imshow('noisy vid',zoom(out_frame))\n",
    "    #if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "    #    break    \n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    pbar.update(1)\n",
    "\n",
    "pbar.close()\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
