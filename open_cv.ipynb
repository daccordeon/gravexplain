{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"open_cv.ipynb\n",
    "James Gardner 2019\n",
    "\n",
    "various basic python3-openCV things\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoom(frame,r=0.5):\n",
    "    rheight = int(frame.shape[0]*r)\n",
    "    rwidth  = int(frame.shape[1]*r)\n",
    "    # caution: order of width, height in resize call\n",
    "    return cv2.resize(frame,(rwidth,rheight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.niser.ac.in/sps/sites/default/files/basic_page/Michelson%20Interferometer_P744%20-%20Optics.pdf\n",
    "# maximum when 2*d*cos(theta) = n*lambda\n",
    "# cos[theta] = n*(lambda/(2*d[t]))\n",
    "# phys_arg is ultimately time varying, lambda/(2*d[t])\n",
    "phys_arg = 0.019\n",
    "total_rings = int(1/phys_arg)\n",
    "angles = np.arccos([n*phys_arg for n in range(1,total_rings+1)])\n",
    "# print(angles*180/np.pi)\n",
    "\n",
    "# pretend that source is 1 away from centre of screen of height 2\n",
    "# tan(theta) gives then gives the fractional radius\n",
    "frac_radii = np.tan(angles)\n",
    "frac_radii = frac_radii[frac_radii < 1]\n",
    "# print(frac_radii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cb5fcf91b66418bba32a72e5dd017b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=150), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# write video of rings\n",
    "fps = 30\n",
    "duration = 5\n",
    "total_frames = 30*5\n",
    "# caution: array[1], array[0]\n",
    "frame_size = 512, 512\n",
    "frame_array_size = 512, 512, 3\n",
    "\n",
    "out = cv2.VideoWriter('green_rings.mp4',cv2.VideoWriter_fourcc(*'mp4v'),fps,frame_size)\n",
    "\n",
    "for i in tqdm(range(total_frames)):\n",
    "    out_frame = np.full(frame_array_size, 255).astype('uint8')\n",
    "    #out_frame[:,i] = [255,255,255]\n",
    "    #out_frame = np.uint8(cv2.add(frameA,frameB))\n",
    "\n",
    "    # cv.Circle(img, center, radius, color, thickness=1) \n",
    "    circle_pos_height = int(frame_size[1]/2)\n",
    "    circle_pos_width  = int(frame_size[0]/2)\n",
    "    min_frame_dim = int(np.min(frame_size)/2)\n",
    "    oscillation_amp = 5\n",
    "    oscillation_speed = i/(2*np.pi)\n",
    "    \n",
    "    for r in frac_radii:\n",
    "        circle_radius = int(r*min_frame_dim + oscillation_amp*np.sin(oscillation_speed))\n",
    "        cv2.circle(out_frame,(circle_pos_width,circle_pos_height),circle_radius,[0,255,0]) \n",
    "    \n",
    "    #cv2.imshow('title',out_frame)\n",
    "    #if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "    #    break\n",
    "    \n",
    "    out.write(out_frame)\n",
    "\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9822a9c517204502a68f8e7b04dd636e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=301), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('tracking_test.mp4')\n",
    "total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "pbar = tqdm(total=total_frames)\n",
    "\n",
    "ret, frame = cap.read()\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "# width, height\n",
    "frame_size = frame.shape[0:2][::-1]\n",
    "\n",
    "out = cv2.VideoWriter('noisy_tracking_test.mp4',cv2.VideoWriter_fourcc(*'mp4v'),fps,frame_size)\n",
    "\n",
    "while ret:\n",
    "    \n",
    "    #out_frame = cv2.flip(frame,1)\n",
    "    noise_level = 10\n",
    "    noisy_frame = np.random.normal(0,noise_level,frame.shape).astype('uint8')\n",
    "    out_frame = cv2.add(frame,noisy_frame)\n",
    "    #out_frame = cv2.add(frame,frame*noisy_frame)\n",
    "    #cv2.normalize(noisy_frame, noisy_frame, 0, 255, cv2.NORM_MINMAX, dtype=-1)\n",
    "    #noisy_image = noisy_image.astype(np.uint8)\n",
    "    #out_frame[out_frame < 0] = 0\n",
    "    #out_frame[out_frame > 255] = 255\n",
    "    out.write(np.uint8(out_frame))\n",
    "    \n",
    "    #cv2.imshow('noisy vid',zoom(out_frame))\n",
    "    #if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "    #    break    \n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    pbar.update(1)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('tracking_test.mp4')\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frame_count = 0\n",
    "pbar = tqdm(total=total_frames)\n",
    "\n",
    "ret, frame = cap.read()\n",
    "\n",
    "while ret:\n",
    "    cv2.imshow('a',zoom(frame[:,:,1]))\n",
    "\n",
    "    # show frame for 30 ms \n",
    "    # 0xFF necessary on 64-bit to truncate waitKey, & is bit-wise\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break    \n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    frame_count += 1\n",
    "    pbar.update(1)\n",
    "\n",
    "pbar.close()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('tracking_test.mp4')\n",
    "total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "pbar = tqdm(total=total_frames)\n",
    "\n",
    "ret, frame = cap.read()\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "# width, height\n",
    "frame_size = frame.shape[0:2][::-1]\n",
    "\n",
    "out = cv2.VideoWriter('noisy_tracking_test.mp4',cv2.VideoWriter_fourcc(*'mp4v'),fps,frame_size)\n",
    "\n",
    "while ret:\n",
    "    \n",
    "    #out_frame = cv2.flip(frame,1)\n",
    "    noise_level = 10\n",
    "    noisy_frame = np.random.normal(0,noise_level,frame.shape).astype('uint8')\n",
    "    out_frame = cv2.add(frame,noisy_frame)\n",
    "    #out_frame = cv2.add(frame,frame*noisy_frame)\n",
    "    #cv2.normalize(noisy_frame, noisy_frame, 0, 255, cv2.NORM_MINMAX, dtype=-1)\n",
    "    #noisy_image = noisy_image.astype(np.uint8)\n",
    "    #out_frame[out_frame < 0] = 0\n",
    "    #out_frame[out_frame > 255] = 255\n",
    "    out.write(np.uint8(out_frame))\n",
    "    \n",
    "    #cv2.imshow('noisy vid',zoom(out_frame))\n",
    "    #if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "    #    break    \n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    pbar.update(1)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# openCV image tracking tutorial\n",
    "# https://opencv-python-tutroals.readthedocs.io/en/latest/\n",
    "# py_tutorials/py_video/py_lucas_kanade/py_lucas_kanade.html\n",
    "# https://stackoverqflow.com/questions/43063320/cv2-calcopticalflowpyrlk-adding-new-points\n",
    "\n",
    "cap = cv2.VideoCapture('noisy_tracking_test.mp4')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "pbar = tqdm(total=total_frames-1)\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Create some random colors\n",
    "color = np.random.randint(0,255,(100,3))\n",
    "\n",
    "# Take first frame and find corners in it\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# # params for ShiTomasi corner detection,\n",
    "# feature_params = dict( maxCorners = 100,\n",
    "#                        qualityLevel = 0.3,\n",
    "#                        minDistance = 7,\n",
    "#                        blockSize = 7 )\n",
    "# p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "\n",
    "# use pinta to get values for selected points\n",
    "p0 = np.array([[1093,548],[1226,544],[1344,547],[1439,553]],np.float32)\n",
    "fav_p = []\n",
    "# print(p0)\n",
    "# 427 175 , 401 187\n",
    "# p0 = np.array([[[427,175]],[[401,187]]])\n",
    "\n",
    "# Create a mask image for drawing purposes\n",
    "mask = np.zeros_like(old_frame)\n",
    "ret, frame = cap.read()\n",
    "\n",
    "after_first = False\n",
    "\n",
    "while ret:\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    # calculate optical flow\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "\n",
    "    # Select good points\n",
    "    #print(p1,p0,st,err)\n",
    "    good_new = p1#[st==1]\n",
    "    good_old = p0#[st==1]\n",
    "\n",
    "    # draw the tracks\n",
    "    for i,(new,old) in enumerate(zip(good_new,good_old)):\n",
    "        a,b = new.ravel()\n",
    "        c,d = old.ravel()\n",
    "        mask = cv2.line(mask, (a,b),(c,d), color[i].tolist(), 2)\n",
    "        frame = cv2.circle(frame,(a,b),5,color[i].tolist(),-1)\n",
    "    img = cv2.add(frame,mask)\n",
    "\n",
    "    cv2.imshow('frame',zoom(img))\n",
    "    if cv2.waitKey(15) & 0xff == ord('q'):\n",
    "        break\n",
    "\n",
    "    # Now update the previous frame and previous points\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1,1,2)\n",
    "    pbar.update(1)\n",
    "    \n",
    "    if after_first:\n",
    "        fav_p.append([p[0][0] for p in p1])    \n",
    "    else:\n",
    "        after_first = True\n",
    "    \n",
    "    ret,frame = cap.read()\n",
    "\n",
    "fav_p = np.array(fav_p)\n",
    "pbar.close()    \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation from tracker_time_series\n",
    "# after_first loses a frame\n",
    "signal_frames = total_frames - 2\n",
    "total_time = (signal_frames-2)/fps\n",
    "signal = fav_p[:,0]\n",
    "t = np.linspace(0,total_time,signal_frames)\n",
    "dt = t[1] - t[0]\n",
    "\n",
    "yf = np.fft.fft(signal)\n",
    "# normalised-absolute value of FT'd signal\n",
    "nrm_abs_yf = 2/signal_frames*np.abs(yf)\n",
    "freq_scale = np.fft.fftfreq(len(yf),dt)\n",
    "# np.fft.fftfreq outputs 0 to +inf then -inf to 0, so :N//2 gets +ve side; wild!\n",
    "freq_prob = nrm_abs_yf[:signal_frames//2]\n",
    "\n",
    "fig, (ax0,ax1) = plt.subplots(2,figsize=(14,14))\n",
    "ax0.plot(t,signal)\n",
    "ax1.plot(freq_scale[:signal_frames//2],freq_prob)\n",
    "ax0.set(title='noisy tracked signal',ylabel='horizonal position, x / frames',xlabel='time, t / s')\n",
    "ax1.set(title='discrete FFT',ylabel='freq strength in signal',xlabel='frequency, f / Hz')\n",
    "plt.savefig('noisy_tracker_signal.pdf',bbox_inches='tight')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread()\n",
    "cap = cv2.VideoCapture('tracking_test.mp4')\n",
    "ret, frame = cap.read()\n",
    "g_frame = frame[:,:,1]\n",
    "# print(g_frame.shape)\n",
    "\n",
    "# cv2.namedWindow('a',cv2.WINDOW_NORMAL)\n",
    "# cv2.namedWindow('a',cv2.WINDOW_AUTOSIZE) \n",
    "cv2.imshow('a',zoom(g_frame))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('tracking_test.mp4')\n",
    "# ret is 'did it successfully return another frame?'\n",
    "\n",
    "while True:\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    try:\n",
    "        grey = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imshow('frame',frame)\n",
    "        cv2.imshow('greyframe',grey)\n",
    "    except:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()        \n",
    "        break    \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('bgr_tester.jpeg')\n",
    "# \"It is important to note that OpenCV reads colors as BGR (Blue Green Red),\n",
    "# where most computer applications read as RGB (Red Green Blue).\n",
    "# Remember this!\"\n",
    "b_channel = img[:,:,0]\n",
    "g_channel = img[:,:,1]\n",
    "r_channel = img[:,:,2]\n",
    "\n",
    "cv2.imshow('b',b_channel)\n",
    "cv2.imshow('g',g_channel)\n",
    "cv2.imshow('r',r_channel)\n",
    "# waitKey argument is the number of milliseconds it waits for\n",
    "if cv2.waitKey(0) == ord('q'):\n",
    "    # cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame splitter!\n",
    "cap = cv2.VideoCapture('tracking_test.mp4')\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frame_count = 0\n",
    "pbar = tqdm(total=total_frames)\n",
    "\n",
    "ret = True\n",
    "while ret:    \n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    #cv2.imwrite('./plots/tracking_test_{:03d}.jpeg'.format(frame_count),frame)\n",
    "    \n",
    "    frame_count += 1\n",
    "    pbar.update(1)\n",
    "    \n",
    "pbar.close()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
