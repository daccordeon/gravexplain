{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"open_cv.ipynb\n",
    "James Gardner 2019\n",
    "\n",
    "various basic python3-openCV things\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoom(frame,r=0.5):\n",
    "    \"\"\"resizes frame while maintaining aspect ratio\"\"\"\n",
    "    rheight = int(frame.shape[0]*r)\n",
    "    rwidth  = int(frame.shape[1]*r)\n",
    "    # caution: order of width, height in resize call\n",
    "    return cv2.resize(frame,(rwidth,rheight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_plot(signal, fps, out_plot_name, out_plot_title=''):\n",
    "    \"\"\"plots fourier spectrum of time series\"\"\"\n",
    "    # implementation from tracker_time_series\n",
    "    # after_first loses a frame\n",
    "    signal_frames = len(signal)\n",
    "    total_time = (signal_frames-2)/fps\n",
    "    t = np.linspace(0,total_time,signal_frames)\n",
    "    dt = t[1] - t[0]\n",
    "\n",
    "    yf = np.fft.fft(signal)\n",
    "    # normalised-absolute value of FT'd signal\n",
    "    nrm_abs_yf = 2/signal_frames*np.abs(yf)\n",
    "    freq_scale = np.fft.fftfreq(len(yf),dt)\n",
    "    # np.fft.fftfreq outputs 0 to +inf then -inf to 0, so :N//2 gets +ve side; wild!\n",
    "    freq_prob = nrm_abs_yf[:signal_frames//2]\n",
    "\n",
    "    fig, (ax0,ax1) = plt.subplots(2,figsize=(14,14))\n",
    "    ax0.plot(t,signal)\n",
    "    ax0.set(title='signal: {}'.format(out_plot_title),ylabel='signal strength',xlabel='time, t')\n",
    "    # filter out the average value gives magnitude of zero freq term\n",
    "    ax1.plot(freq_scale[:signal_frames//2][2:],freq_prob[2:])\n",
    "    ax1.set(title='discrete FFT',ylabel='freq strength in signal',xlabel='frequency, f')\n",
    "    # REMEMBER TO CHANGE OUT FILENAME\n",
    "    plt.savefig(out_plot_name,bbox_inches='tight')\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_at_point(filename, point=None, return_series=False,\n",
    "                    produce_plot=False, out_plot_name='tmp.pdf'):\n",
    "    \"\"\"green channel intensity at point in the interference pattern\n",
    "    also plots time series and spectrum thereof\n",
    "    aka: run_dog_run, won't produce/return anything unless you tell it to\"\"\"\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    pbar = tqdm(total=total_frames-1)\n",
    "\n",
    "    point_intensity = []\n",
    "    ret, frame = cap.read()\n",
    "    # default to centre of frame\n",
    "    if point is None:\n",
    "        point = tuple([int(i/2) for i in frame.shape[:2]])\n",
    "\n",
    "    while ret:\n",
    "        # centre time series\n",
    "        # use green channel since it has the greatest weight anyway\n",
    "        # https://en.wikipedia.org/wiki/Relative_luminance\n",
    "        point_intensity.append(frame[point][1])\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "    cap.release()\n",
    "\n",
    "    if produce_plot:\n",
    "        fourier_plot(point_intensity, fps, out_plot_name, filename)\n",
    "    if return_series:\n",
    "        return point_intensity, fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_spectrum(signal, fps):\n",
    "    \"\"\"returns fourier spectrum of time series\"\"\"\n",
    "    # implementation from tracker_time_series\n",
    "    # after_first loses a frame\n",
    "    signal_frames = len(signal)\n",
    "    total_time = (signal_frames-2)/fps\n",
    "    t = np.linspace(0,total_time,signal_frames)\n",
    "    dt = t[1] - t[0]\n",
    "\n",
    "    yf = np.fft.fft(signal)\n",
    "    # normalised-absolute value of FT'd signal\n",
    "    nrm_abs_yf = 2/signal_frames*np.abs(yf)\n",
    "    freq_scale = np.fft.fftfreq(len(yf),dt)\n",
    "    # np.fft.fftfreq outputs 0 to +inf then -inf to 0, so :N//2 gets +ve side; wild!\n",
    "    freq_prob = nrm_abs_yf[:signal_frames//2]\n",
    "    \n",
    "    return freq_prob, freq_scale[:signal_frames//2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply viterbi to binned long capture\n",
    "# -> look at mock_continuous_signal.ipynb snippets below\n",
    "\n",
    "# capture long video, slowly changing the frequency throughout (up then back down)\n",
    "# bin into 30 second slices, or 40 bins?\n",
    "# fourier transform\n",
    "# viterbi to recover meandering frequency\n",
    "\n",
    "# grid is down, now apply viterbi!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a saved video called expt_5.mp4\n",
    "# instead of splicing into 40 smaller videos, e.g. expt_5_xx.mp4\n",
    "# just create one time series and split it later\n",
    "filename = 'expt_0.mp4'\n",
    "long_signal, fps = series_at_point(filename,return_series=True)\n",
    "total_frames = len(long_signal)\n",
    "# i.e. number of bins/chunks\n",
    "long_timesteps = 5\n",
    "bin_total_frames = total_frames//long_timesteps\n",
    "\n",
    "# tosses away remainder\n",
    "bin_signals = [long_signal[i: i+bin_total_frames]\n",
    "               for i in range(0, total_frames-bin_total_frames, bin_total_frames)]\n",
    "\n",
    "# form up the grid\n",
    "grid = np.zeros((bin_total_frames//2,long_timesteps))\n",
    "\n",
    "for i,signal in enumerate(bin_signals):\n",
    "    col = fourier_spectrum(signal, fps)[0]\n",
    "    grid[:,i] = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"stitches frequency distribution of sinusoidal signals into a\n",
    "grid with the frequency slowly changing (meandering) through time,\n",
    "then applies viterbi's algorithm to try to recover the frequency path\"\"\"\n",
    "# long time as opposed to the short 0 to 2*pi interval of each signal\n",
    "long_timesteps = 100\n",
    "bin_time = np.linspace(0,1,long_timesteps)\n",
    "# meander is the long scale change in the sine frequency\n",
    "meander_amp = 20\n",
    "meander_decay = 2\n",
    "meander_freq = 2\n",
    "meander = lambda x: meander_amp*(\n",
    "    np.exp(-x*meander_decay)*\n",
    "    np.sin(meander_freq*2*np.pi*x))\n",
    "# connections back a timestep made for all indicies with plus/minus scanning_range\n",
    "# this limits how much the viterbi path will change frequency at each timestep made\n",
    "scanning_range = 10\n",
    "initial_frequency = 20\n",
    "\n",
    "# halve total number of points due to fft on real function\n",
    "grid = np.zeros((SineSignal.n_t//2,long_timesteps))\n",
    "# print('grid is:',grid.shape)\n",
    "# signal meanders from the initial frequency\n",
    "wandering_freqs = (initial_frequency+meander(bin_time))\n",
    "# post_freq is the maximum frequency in the column\n",
    "# if the resultant plot is exact, then the recovery is perfect\n",
    "post_freq = []\n",
    "\n",
    "for i,f in tqdm(enumerate(wandering_freqs)):\n",
    "    thing_f = SineSignal(f)\n",
    "    col = thing_f.freq_prob\n",
    "    # [i][j] same as [:,j][i] same as [i,j]\n",
    "    grid[:,i] = col\n",
    "    post_freq.append(thing_f.inj_freq[col.argmax()])\n",
    "\n",
    "# normalised grid, trying to maximise produce of values\n",
    "ngrid  = grid/np.max(grid)\n",
    "# logarithm avoids underflow, maximise sum of log(value)'s\n",
    "lngrid = np.log(ngrid)\n",
    "\n",
    "score_grid  = np.copy(lngrid)\n",
    "pathfinder_flag = len(lngrid[:,0]) #=500\n",
    "# pathfinder stores the survivor paths, to allow back-tracking through\n",
    "pathfinder = np.full(np.shape(lngrid), pathfinder_flag)\n",
    "# pathfinder flag+1 for reaching the first, 0-index column        \n",
    "pathfinder[:,0] = pathfinder_flag+1       \n",
    "\n",
    "# the viterbi algorithm, through time finding the best path to each node\n",
    "# see: https://www.youtube.com/watch?v=6JVqutwtzmo\n",
    "for j in tqdm(range(1,long_timesteps)): #range(100)\n",
    "    for i in range(len(score_grid[:,j])): #range(500)\n",
    "        # index values for where to look relative to i in previous column\n",
    "        k_a = max(0, i-scanning_range) \n",
    "        k_b = min(len(score_grid[:,j-1])-1,\n",
    "                  i+scanning_range)\n",
    "        #print(k_a,k_b)\n",
    "        window = score_grid[:,j-1][k_a:k_b+1]\n",
    "        # find the best thing nearby in the previous column ...\n",
    "        window_score = np.max(window)\n",
    "        window_ref   = k_a+np.argmax(window)\n",
    "        # ... and take note of it, summing the log(value)'s\n",
    "        score_grid[i][j] += window_score\n",
    "        pathfinder[i][j] = window_ref \n",
    "\n",
    "# look at the very last column, and find the best ending for the path\n",
    "best_score  = np.max(score_grid[:,-1])\n",
    "best_end = np.argmax(score_grid[:,-1])\n",
    "# now need to retrace the steps through the grid\n",
    "best_path_back = np.full(long_timesteps,pathfinder_flag+2)\n",
    "best_path_back[-1] = best_end\n",
    "\n",
    "# path_grid is the binary image of the viterbi path taken\n",
    "path_grid = np.zeros(np.shape(ngrid))\n",
    "tmp_path = pathfinder[best_end][-1]\n",
    "\n",
    "for j in tqdm(reversed(range(0,long_timesteps-1))):\n",
    "    path_grid[tmp_path][j] = 1\n",
    "    # take pathfinder value in current step and follow it backwards\n",
    "    best_path_back[j] = tmp_path    \n",
    "    tmp_path = pathfinder[tmp_path][j]\n",
    "\n",
    "# make sure we got all the way home\n",
    "assert tmp_path == pathfinder_flag+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"saves plots of meandering frequency, the signal grid, and the recovered viterbi path \"\"\"\n",
    "# need ngrid, lngrid, path_grid\n",
    "plt.figure(figsize=(7,14))\n",
    "plt.imshow(ngrid, cmap='viridis')\n",
    "plt.gca().xaxis.tick_top()\n",
    "plt.gca().xaxis.set_label_position('top')\n",
    "cbar = plt.colorbar() \n",
    "cbar.set_label('frequency probability distribution')\n",
    "plt.title('grid of signals in frequency domain as frequency changes')\n",
    "plt.ylabel('signal frequency bins')\n",
    "plt.xlabel('long time bins')\n",
    "plt.savefig('expt_signal_grid_raw.pdf',bbox_inches='tight')\n",
    "plt.clf()\n",
    "\n",
    "plt.figure(figsize=(7,14))\n",
    "plt.imshow(lngrid, cmap='viridis')\n",
    "plt.gca().xaxis.tick_top()\n",
    "plt.gca().xaxis.set_label_position('top')        \n",
    "cbar = plt.colorbar() \n",
    "cbar.set_label('log(frequency) probability distribution')\n",
    "plt.title('grid of signals in log(frequency) domain as frequency changes')\n",
    "plt.ylabel('signal frequency bins')\n",
    "plt.xlabel('long time bins')\n",
    "plt.savefig('expt_lnwandering.pdf',bbox_inches='tight')\n",
    "plt.clf()\n",
    "\n",
    "plt.figure(figsize=(7,14))\n",
    "plt.imshow(path_grid, cmap='viridis')\n",
    "plt.gca().xaxis.tick_top()\n",
    "plt.gca().xaxis.set_label_position('top')        \n",
    "plt.title('viterbi path through signal frequency grid')\n",
    "plt.ylabel('signal frequency bins')\n",
    "plt.xlabel('long time bins')\n",
    "plt.savefig('expt_viterbi_path.pdf',bbox_inches='tight')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# track manually found first ring points\n",
    "expt_nums = '4_0209','4_0580','4_0581','4_1099','4_2014'\n",
    "points = (200,250),(230,270),(240,250),(220,310),(230,320)\n",
    "# zexpt_0: y, x = 280, 355\n",
    "\n",
    "for i in range(len(expt_nums)):\n",
    "    series_at_point('expt_{}.mp4'.format(expt_nums[i]), points[i],\n",
    "                    produce_plot=True, out_plot_name='expt_{}.pdf'.format(expt_nums[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"tracks points in video\"\"\"\n",
    "# openCV image tracking tutorial\n",
    "# https://opencv-python-tutroals.readthedocs.io/en/latest/\n",
    "# py_tutorials/py_video/py_lucas_kanade/py_lucas_kanade.html\n",
    "# https://stackoverqflow.com/questions/43063320/cv2-calcopticalflowpyrlk-adding-new-points\n",
    "\n",
    "# cap = cv2.VideoCapture('noisy_tracking_test.mp4')\n",
    "cap = cv2.VideoCapture('expt_1_shake.mp4')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "pbar = tqdm(total=total_frames-1)\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Create some random colors\n",
    "color = np.random.randint(0,255,(100,3))\n",
    "\n",
    "# Take first frame and find corners in it\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# # params for ShiTomasi corner detection,\n",
    "# feature_params = dict( maxCorners = 100,\n",
    "#                        qualityLevel = 0.3,\n",
    "#                        minDistance = 7,\n",
    "#                        blockSize = 7 )\n",
    "# p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "\n",
    "# use pinta to get values for selected points\n",
    "# tracking_test\n",
    "# p0 = np.array([[1093,548],[1226,544],[1344,547],[1439,553]],np.float32)\n",
    "# expt_0: 280,355\n",
    "# p0 = np.array([[215,275]]).astype('float32')\n",
    "# expt_1: 453,943 <-centres\n",
    "p0 = np.array([[735,455]]).astype('float32')\n",
    "# expt_2: 453,946\n",
    "# p0 = np.array([[720,450]]).astype('float32')\n",
    "# expt_3: 458,938\n",
    "# p0 = np.array([[734,450]]).astype('float32')\n",
    "\n",
    "# y, x\n",
    "# ring_centre = 280, 355 #expt_0\n",
    "ring_centre = 455, 940 #expt_1,2,3\n",
    "\n",
    "tracked_points = []\n",
    "# print(p0)\n",
    "# 427 175 , 401 187\n",
    "# p0 = np.array([[[427,175]],[[401,187]]])\n",
    "\n",
    "# Create a mask image for drawing purposes\n",
    "mask = np.zeros_like(old_frame)\n",
    "ret, frame = cap.read()\n",
    "\n",
    "after_first = False\n",
    "\n",
    "while ret:\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    # calculate optical flow\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "\n",
    "    # Select good points\n",
    "    #print(p1,p0,st,err)\n",
    "    good_new = p1#[st==1]\n",
    "    good_old = p0#[st==1]\n",
    "\n",
    "    # draw the tracks\n",
    "    for i,(new,old) in enumerate(zip(good_new,good_old)):\n",
    "        a,b = new.ravel()\n",
    "        c,d = old.ravel()\n",
    "        mask = cv2.line(mask, (a,b),(c,d), color[i].tolist(), 2)\n",
    "        frame = cv2.circle(frame,(a,b),5,color[i].tolist(),-1)\n",
    "    img = cv2.add(frame,mask)\n",
    "\n",
    "    #cv2.imshow('title',zoom(img))\n",
    "    #if cv2.waitKey(15) & 0xff == ord('q'):\n",
    "    #    break\n",
    "\n",
    "    # Now update the previous frame and previous points\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1,1,2)\n",
    "    pbar.update(1)\n",
    "    \n",
    "    if after_first:\n",
    "        tracked_points.append([p[0] for p in p1])    \n",
    "    else:\n",
    "        after_first = True\n",
    "    \n",
    "    ret,frame = cap.read()\n",
    "\n",
    "tracked_points = np.array(tracked_points)\n",
    "pbar.close()\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "\n",
    "# ring_centre = y, x\n",
    "tracker_0 = tracked_points#[:,:,0]\n",
    "dist_to_ring_centre = lambda y, x: ((y-ring_centre[0])**2+(x-ring_centre[1])**2)**0.5\n",
    "tracker_0_radius = np.array([dist_to_ring_centre(*p[0]) for p in tracker_0])\n",
    "\n",
    "fourier_plot(tracker_0_radius, fps, 'expt_1.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"save a zoomed version of the video\"\"\"\n",
    "cap = cv2.VideoCapture('expt_0.mp4')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "frame_count = 0\n",
    "pbar = tqdm(total=total_frames)\n",
    "\n",
    "# width: 600-1400, height: 0-550\n",
    "ret, frame = cap.read()\n",
    "zframe = frame[0:550,600:1400]\n",
    "\n",
    "# width, height\n",
    "frame_size = zframe.shape[0:2][::-1]\n",
    "\n",
    "out = cv2.VideoWriter('zexpt_0.mp4',cv2.VideoWriter_fourcc(*'mp4v'),fps,frame_size)\n",
    "\n",
    "while ret:\n",
    "    zframe = frame[0:550,600:1400]    \n",
    "    out.write(np.uint8(zframe))    \n",
    "   \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    frame_count += 1\n",
    "    pbar.update(1)\n",
    "\n",
    "pbar.close()\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"creates mock rings\"\"\"\n",
    "# https://www.niser.ac.in/sps/sites/default/files/basic_page/Michelson%20Interferometer_P744%20-%20Optics.pdf\n",
    "# maximum when 2*d*cos(theta) = n*lambda\n",
    "# cos[theta] = n*(lambda/(2*d[t]))\n",
    "# phys_arg is ultimately time varying, lambda/(2*d[t])\n",
    "phys_arg = 0.019\n",
    "total_rings = int(1/phys_arg)\n",
    "angles = np.arccos([n*phys_arg for n in range(1,total_rings+1)])\n",
    "# print(angles*180/np.pi)\n",
    "\n",
    "# pretend that source is 1 away from centre of screen of height 2\n",
    "# tan(theta) gives then gives the fractional radius\n",
    "frac_radii = np.tan(angles)\n",
    "frac_radii = frac_radii[frac_radii < 1]\n",
    "# print(frac_radii)\n",
    "\n",
    "# write video of rings\n",
    "fps = 30\n",
    "duration = 20\n",
    "total_frames = 30*5\n",
    "# caution: array[1], array[0]\n",
    "frame_size = 512, 512\n",
    "frame_array_size = 512, 512, 3\n",
    "\n",
    "out = cv2.VideoWriter('green_rings.mp4',cv2.VideoWriter_fourcc(*'mp4v'),fps,frame_size)\n",
    "\n",
    "for i in tqdm(range(total_frames)):\n",
    "    out_frame = np.full(frame_array_size, 255).astype('uint8')\n",
    "    #out_frame[:,i] = [255,255,255]\n",
    "    #out_frame = np.uint8(cv2.add(frameA,frameB))\n",
    "\n",
    "    # cv.Circle(img, center, radius, color, thickness=1) \n",
    "    circle_pos_height = int(frame_size[1]/2)\n",
    "    circle_pos_width  = int(frame_size[0]/2)\n",
    "    min_frame_dim = int(np.min(frame_size)/2)\n",
    "    oscillation_amp = 5\n",
    "    oscillation_speed = i/(2*np.pi)\n",
    "    \n",
    "    for r in frac_radii:\n",
    "        circle_radius = int(r*min_frame_dim + oscillation_amp*np.sin(oscillation_speed))\n",
    "        cv2.circle(out_frame,(circle_pos_width,circle_pos_height),circle_radius,[0,255,0]) \n",
    "    \n",
    "    #cv2.imshow('title',out_frame)\n",
    "    #if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "    #    break\n",
    "    \n",
    "    out.write(out_frame)\n",
    "\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"adds noise to a video\"\"\"\n",
    "cap = cv2.VideoCapture('green_rings.mp4')\n",
    "total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "pbar = tqdm(total=total_frames-1)\n",
    "\n",
    "ret, frame = cap.read()\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "# width, height\n",
    "frame_size = frame.shape[0:2][::-1]\n",
    "\n",
    "out = cv2.VideoWriter('noisy_green_rings.mp4',cv2.VideoWriter_fourcc(*'mp4v'),fps,frame_size)\n",
    "\n",
    "while ret:\n",
    "    \n",
    "    #out_frame = cv2.flip(frame,1)\n",
    "    noise_level = 10\n",
    "    noisy_frame = np.random.normal(0,noise_level,frame.shape).astype('uint8')\n",
    "    out_frame = cv2.add(frame,noisy_frame)\n",
    "    #out_frame = cv2.add(frame,frame*noisy_frame)\n",
    "    #cv2.normalize(noisy_frame, noisy_frame, 0, 255, cv2.NORM_MINMAX, dtype=-1)\n",
    "    #noisy_image = noisy_image.astype(np.uint8)\n",
    "    #out_frame[out_frame < 0] = 0\n",
    "    #out_frame[out_frame > 255] = 255\n",
    "    out.write(np.uint8(out_frame))\n",
    "    \n",
    "    #cv2.imshow('noisy vid',zoom(out_frame))\n",
    "    #if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "    #    break    \n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    pbar.update(1)\n",
    "\n",
    "pbar.close()\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
